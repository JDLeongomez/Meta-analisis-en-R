
@article{veveaGeneralLinearModel1995,
  title = {A General Linear Model for Estimating Effect Size in the Presence of Publication Bias},
  author = {Vevea, Jack L. and Hedges, Larry V.},
  year = {1995},
  month = sep,
  journal = {Psychometrika},
  volume = {60},
  number = {3},
  pages = {419--435},
  issn = {1860-0980},
  doi = {10.1007/BF02294384},
  abstract = {When the process of publication favors studies with smallp-values, and hence large effect estimates, combined estimates from many studies may be biased. This paper describes a model for estimation of effect size when there is selection based on one-tailedp-values. The model employs the method of maximum likelihood in the context of a mixed (fixed and random) effects general linear model for effect sizes. It offers a test for the presence of publication bias, and corrected estimates of the parameters of the linear model for effect magnitude. The model is illustrated using a well-known data set on the benefits of psychotherapy.},
  langid = {english}
}

@article{veveaPublicationBiasResearch2005,
  title = {Publication Bias in Research Synthesis: Sensitivity Analysis Using a Priori Weight Functions},
  shorttitle = {Publication Bias in Research Synthesis},
  author = {Vevea, Jack L. and Woods, Carol M.},
  year = {2005},
  month = dec,
  journal = {Psychological Methods},
  volume = {10},
  number = {4},
  pages = {428--443},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.10.4.428},
  abstract = {Publication bias, sometimes known as the "file-drawer problem" or "funnel-plot asymmetry," is common in empirical research. The authors review the implications of publication bias for quantitative research synthesis (meta-analysis) and describe existing techniques for detecting and correcting it. A new approach is proposed that is suitable for application to meta-analytic data sets that are too small for the application of existing methods. The model estimates parameters relevant to fixed-effects, mixed-effects or random-effects meta-analysis contingent on a hypothetical pattern of bias that is fixed independently of the data. The authors illustrate this approach for sensitivity analysis using 3 data sets adapted from a commonly cited reference work on research synthesis (H. M. Cooper \& L. V. Hedges, 1994).},
  langid = {english},
  pmid = {16392998},
  keywords = {Data Interpretation; Statistical,Humans,Meta-Analysis as Topic,Models; Psychological,Publishing,Research,Research Design,Sensitivity and Specificity}
}

@article{leongomezMetacCorr2022,
  title = {{Meta-an\'alisis de correlaciones en R}},
  author = {Leong{\'o}mez, Juan David},
  year = {2022},
  month = feb,
  journal = {{Zenodo}},
  doi = {10.5281/zenodo.5640182},
  langid = {spanish}
}

@article{molloy2013,
	title = {Conscientiousness and Medication Adherence: A Meta-analysis},
	author = {{Molloy}, {G. J.} and {O{\textquoteright}Carroll}, {R. E.} and {Ferguson}, {E.}},
	year = {2013},
	month = {06},
	date = {2013-06-20},
	journal = {Annals of Behavioral Medicine},
	pages = {92--101},
	volume = {47},
	number = {1},
	doi = {10.1007/s12160-013-9524-4},
	url = {http://dx.doi.org/10.1007/s12160-013-9524-4},
	langid = {en}
}

@article{fisherRobumetaRpackageRobust2015,
  title = {Robumeta: {{An R}}-Package for Robust Variance Estimation in Meta-Analysis},
  shorttitle = {Robumeta},
  author = {Fisher, Zachary and Tipton, Elizabeth},
  year = {2015},
  month = mar,
  journal = {arXiv:1503.02220 [stat]},
  eprint = {1503.02220},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Meta-regression models are commonly used to synthesize and compare effect sizes. Unfortunately, traditional meta-regression methods are ill-equipped to handle the complex and often unknown correlations among non-independent effect sizes. Robust variance estimation (RVE) is a recently proposed meta-analytic method for dealing with dependent effect sizes. The robumeta package provides functions for performing robust variance meta-regression using both large and small sample RVE estimators under various weighting schemes. These methods are distribution free and provide valid point estimates, standard errors and hypothesis tests even when the degree and structure of dependence between effect sizes is unknown.},
  archiveprefix = {arXiv},
  file = {D\:\\GDrive\\Zotero\\arXiv1503.02220 [stat]\\Fisher,Tipton_2015_robumeta.pdf;D\:\\Zotero Library\\storage\\YZ86LECN\\1503.html}
}

@Manual{KossmeierMetaviz,
    title = {metaviz: Forest Plots, Funnel Plots, and Visual Funnel Plot Inference for Meta-Analysis},
    author = {Michael Kossmeier and Ulrich S. Tran and Martin Voracek},
    year = {2020},
    note = {R package version 0.3.1},
    url = {https://CRAN.R-project.org/package=metaviz},
  }

@article{viechtbauer2010,
	title = {Conducting Meta-Analyses in {{R}} with the metafor Package},
	author = {{Viechtbauer}, {Wolfgang}},
	year = {2010},
	date = {2010},
	journal = {Journal of Statistical Software},
	volume = {36},
	number = {3},
	doi = {10.18637/jss.v036.i03},
	url = {http://dx.doi.org/10.18637/jss.v036.i03},
	langid = {en}
}

@misc{quintanaHowPerformMetaanalysis2021,
  title = {How to Perform a Meta-Analysis in {{R}}},
  author = {Quintana, Daniel S.},
  year = {2021},
  month = may,
  day = 23,
	organization = {[Archivo de {V\'ideo}]. YouTube.},
  howpublished = {\url{https://youtu.be/lH4VZMTEZSc}}
}

@misc{leongomezMetaanalysis2021,
  title = {Hacer meta-análisis en jamovi es muy fácil},
  author = {Leongómez, Juan David},
  year = {2021},
  month = may,
  day = 9,
	organization = {[Archivo de {V\'ideo}]. YouTube.},
  howpublished = {\url{https://youtu.be/ntBbkOn9D_o}}
}

@incollection{borensteinIdentifyingQuantifyingHeterogeneity2009,
  title = {Identifying and {{Quantifying Heterogeneity}}},
  booktitle = {Introduction to {{Meta}}-{{Analysis}}},
  author = {Borenstein, Michael and Hedges, Larry V. and Higgns, Julian P. T. and Rothstein, Hannah R.},
  year = {2009},
  pages = {107--125},
  publisher = {Wiley},
  doi = {10.1002/9780470743386.ch16},
  abstract = {This chapter contains sections titled: Introduction Isolating the variation in true effects Computing Q Estimating {$\tau$}2 The I2 statistic Comparing the measures of heterogeneity Confidence intervals for {$\tau$}2 Confidence intervals (or uncertainty intervals) for I2 Summary points},
  chapter = {16},
  isbn = {978-0-470-74338-6},
  language = {en},
  keywords = {chi-squared distribution,I2 statistic,isolating the variation in true effects,testing assumption of homogeneity in effects,weighted sum of squares (WSS)},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470743386.ch16}
}


@article{eggerBiasMetaanalysisDetected1997,
  title = {Bias in Meta-Analysis Detected by a Simple, Graphical Test},
  author = {Egger, Matthias and Smith, George Davey and Schneider, Martin and Minder, Christoph},
  year = {1997},
  month = sep,
  journal = {BMJ},
  volume = {315},
  number = {7109},
  pages = {629--634},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.315.7109.629},
  abstract = {Objective: Funnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test of asymmetry of funnel plots predicts discordance of results when meta-analyses are compared to large trials, and we assessed the prevalence of bias in published meta-analyses. Design: Medline search to identify pairs consisting of a meta-analysis and a single large trial (concordance of results was assumed if effects were in the same direction and the meta-analytic estimate was within 30\% of the trial); analysis of funnel plots from 37 meta-analyses identified from a hand search of four leading general medicine journals 1993-6 and 38 meta-analyses from the second 1996 issue of the Cochrane Database of Systematic Reviews. Main outcome measure: Degree of funnel plot asymmetry as measured by the intercept from regression of standard normal deviates against precision. Results: In the eight pairs of meta-analysis and large trial that were identified (five from cardiovascular medicine, one from diabetic medicine, one from geriatric medicine, one from perinatal medicine) there were four concordant and four discordant pairs. In all cases discordance was due to meta-analyses showing larger effects. Funnel plot asymmetry was present in three out of four discordant pairs but in none of concordant pairs. In 14 (38\%) journal meta-analyses and 5 (13\%) Cochrane reviews, funnel plot asymmetry indicated that there was bias. Conclusions: A simple analysis of funnel plots provides a useful test for the likely presence of bias in meta-analyses, but as the capacity to detect bias will be limited when meta-analyses are based on a limited number of small trials the results from such analyses should be treated with considerable caution. Key messages Systematic reviews of randomised trials are the best strategy for appraising evidence; however, the findings of some meta-analyses were later contradicted by large trialsFunnel plots, plots of the trials' effect estimates against sample size, are skewed and asymmetrical in the presence of publication bias and other biasesFunnel plot asymmetry, measured by regression analysis, predicts discordance of results when meta-analyses are compared with single large trialsFunnel plot asymmetry was found in 38\% of meta-analyses published in leading general medicine journals and in 13\% of reviews from the Cochrane Database of Systematic ReviewsCritical examination of systematic reviews for publication and related biases should be considered a routine procedure},
  chapter = {Paper},
  copyright = {\textcopyright{} 1997 BMJ Publishing Group Ltd.},
  language = {en},
  pmid = {9310563},
  file = {D\:\\GDrive\\Zotero\\BMJ\\Egger et al_1997_Bias in meta-analysis detected by a simple, graphical test.pdf;D\:\\Zotero Library\\storage\\7K4KHTQW\\629.html}
}





@article{eggerBiasMetaanalysisDetected1997,
  title = {Bias in Meta-Analysis Detected by a Simple, Graphical Test},
  author = {Egger, Matthias and Smith, George Davey and Schneider, Martin and Minder, Christoph},
  year = {1997},
  month = sep,
  journal = {BMJ},
  volume = {315},
  number = {7109},
  pages = {629--634},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.315.7109.629},
  abstract = {Objective: Funnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test of asymmetry of funnel plots predicts discordance of results when meta-analyses are compared to large trials, and we assessed the prevalence of bias in published meta-analyses. Design: Medline search to identify pairs consisting of a meta-analysis and a single large trial (concordance of results was assumed if effects were in the same direction and the meta-analytic estimate was within 30\% of the trial); analysis of funnel plots from 37 meta-analyses identified from a hand search of four leading general medicine journals 1993-6 and 38 meta-analyses from the second 1996 issue of the Cochrane Database of Systematic Reviews. Main outcome measure: Degree of funnel plot asymmetry as measured by the intercept from regression of standard normal deviates against precision. Results: In the eight pairs of meta-analysis and large trial that were identified (five from cardiovascular medicine, one from diabetic medicine, one from geriatric medicine, one from perinatal medicine) there were four concordant and four discordant pairs. In all cases discordance was due to meta-analyses showing larger effects. Funnel plot asymmetry was present in three out of four discordant pairs but in none of concordant pairs. In 14 (38\%) journal meta-analyses and 5 (13\%) Cochrane reviews, funnel plot asymmetry indicated that there was bias. Conclusions: A simple analysis of funnel plots provides a useful test for the likely presence of bias in meta-analyses, but as the capacity to detect bias will be limited when meta-analyses are based on a limited number of small trials the results from such analyses should be treated with considerable caution. Key messages Systematic reviews of randomised trials are the best strategy for appraising evidence; however, the findings of some meta-analyses were later contradicted by large trialsFunnel plots, plots of the trials' effect estimates against sample size, are skewed and asymmetrical in the presence of publication bias and other biasesFunnel plot asymmetry, measured by regression analysis, predicts discordance of results when meta-analyses are compared with single large trialsFunnel plot asymmetry was found in 38\% of meta-analyses published in leading general medicine journals and in 13\% of reviews from the Cochrane Database of Systematic ReviewsCritical examination of systematic reviews for publication and related biases should be considered a routine procedure},
  chapter = {Paper},
  copyright = {\textcopyright{} 1997 BMJ Publishing Group Ltd.},
  language = {en},
  pmid = {9310563},
  file = {D\:\\GDrive\\Zotero\\BMJ\\Egger et al_1997_Bias in meta-analysis detected by a simple, graphical test.pdf;D\:\\Zotero Library\\storage\\7K4KHTQW\\629.html}
}





@incollection{schwarzerSmallStudyEffectsMetaAnalysis2015,
  title = {Small-{{Study Effects}} in {{Meta}}-{{Analysis}}},
  booktitle = {Meta-{{Analysis}} with {{R}}},
  author = {Schwarzer, Guido and Carpenter, James R. and R{\"u}cker, Gerta},
  editor = {Schwarzer, Guido and Carpenter, James R. and R{\"u}cker, Gerta},
  year = {2015},
  series = {Use {{R}}!},
  pages = {107--141},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-21416-0_5},
  abstract = {This chapter describes small-study effects in meta-analysis and how the issues they raise may be addressed. ``Small-study effects'' is a generic term for the phenomenon that smaller studies sometimes show different, often larger, treatment effects than large ones. This notion was coined by Sterne et al. [55]. One possible, probably the most well-known, reason is publication bias. This is said to occur when the chance of a smaller study being published is increased if it shows a stronger effect [3, 41, 52]. This can happen for a number of reasons, for example authors may be more likely to submit studies with ``significant'' results for publication or journals may be more likely to publish smaller studies if they have ``significant'' results. If this occurs, it in turn biases the results of meta-analyses and systematic reviews. There are a number of other possible reasons for small-study effects. One is selective reporting of the most favourable outcomes, known as outcome selection bias or outcome reporting bias [8, 9, 18, 61]. Another possible cause of small-study effects is clinical heterogeneity between patients in large and small studies; e.g., patients in smaller studies may have been selected so that a favourable outcome of the experimental treatment may be expected. In the case of a binary outcome, also a mathematical artefact arises from the fact that for the odds ratio or the risk ratio, the variance of the treatment effect estimate is not independent of the estimate itself [47]. This problem will be discussed in Sect. 5.2.2. Lastly, it can never be ruled out that small-study effects result from mere coincidence [42]. Empirical studies have established evidence for these and other kinds of bias [19, 42, 53]. There is a vast range of tests for small-study effects [4, 20, 24, 38, 43, 48], most of them based on a funnel plot which will be introduced in Sect. 5.1.1.},
  isbn = {978-3-319-21416-0},
  language = {en},
  keywords = {Funnel Plot Asymmetry,Large Standard Error,Publication Bias,Treatment Effect Estimate,Treatment Estimate},
  file = {D\:\\GDrive\\Zotero\\Meta-Analysis with R\\Schwarzer et al_2015_Small-Study Effects in Meta-Analysis.pdf}
}



