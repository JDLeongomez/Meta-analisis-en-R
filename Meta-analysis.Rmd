---
title: 'Meta-análisis de correlaciones y meta-regresión en R:'
subtitle: 'Guía práctica'
author:
  - name: Juan David Leongómez \orcidlink{0000-0002-0092-6298}
    correspondence: false
date: "`r Sys.setlocale('LC_TIME');format(Sys.Date(),'%d %B, %Y')`"
output:
  bookdown::pdf_document2:
    number_sections: yes
    keep_tex:  true
    toc: no
    pandoc_args:
      - '--lua-filter=lua/scholarly-metadata.lua'
      - '--lua-filter=lua/author-info-blocks.lua'
      - '--highlight-style=theme/my_style.theme'
classoption: 
      - bookmarksnumbered
editor_options:
  chunk_output_type: console
geometry: margin=2cm
header-includes: 
  \usepackage{setspace}
  \usepackage{float} 
  \floatplacement{figure}{H}
  \usepackage[utf8]{inputenc}
  \usepackage{fancyhdr}
  \pagestyle{fancy}
  \lhead{Juan David Leongómez}
  \rhead{\textit{Meta-análisis de correlaciones en {R:} Guía práctica}}
  \rfoot{\footnotesize{{doi:}
    \href{https://doi.org/10.5281/zenodo.5640182}{10.5281/zenodo.5640182}}}
  \lfoot{\footnotesize{Versión 2}}
  \renewcommand{\abstractname}{Descripción}
  \usepackage[spanish]{babel}
  \usepackage{hanging}
  \usepackage{amsthm,amssymb,amsfonts}
  \usepackage{tikz,lipsum,lmodern}
  \usepackage[most]{tcolorbox}
  \usepackage{fontawesome5}
  \usepackage{svg}
  \usepackage{multirow,booktabs,caption}
  \renewcommand\spanishtablename{Tabla}
  \DeclareCaptionLabelSeparator*{spaced}{\\[1ex]}
  \DeclareCaptionLabelSeparator{point}{. }
  \captionsetup[table]{labelfont=bf,
    textfont=it,
    format=plain,
    justification=justified,
    singlelinecheck=false,
    labelsep=spaced,
    skip=5pt}
  \captionsetup[figure]{labelfont=bf,
    format=plain,
    justification=justified,
    singlelinecheck=false,labelsep=point,skip=5pt}
  \captionsetup[figure]{font=small}
  \usepackage{orcidlink}
  \definecolor{iacol}{RGB}{246, 130, 18}
  \definecolor{iacoldark}{RGB}{246, 100, 18}
always_allow_html: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
urlcolor: blue
linkcolor: iacoldark
link-citations: true
bibliography: bib/references.bib
---

```{=latex}
\newtcolorbox[auto counter]{ROut}[2][]{
                lower separated=false,
                colback=white,
                colframe=iacol,
                fonttitle=\bfseries,
                colbacktitle=iacol,
                coltitle=black,
                boxrule=1pt,
                sharp corners,
                breakable,
                enhanced,
                attach boxed title to top left={yshift=-0.1in,xshift=0.15in},
                boxed title style={boxrule=0pt,colframe=white,},
              title=#2,#1}
```

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(comment = NA)
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options){
  out <- def_hook(x, options)
  return(paste("\\begin{ROut}{Consola de R: Output~\\thetcbcounter}
                \\begin{footnotesize}
                \\begin{verbatim}", 
               x,
               "\\end{verbatim}
                \\end{footnotesize}
                \\end{ROut}"))
})
library(robumeta)
library(metafor)
library(tidyverse)
library(ggpubr)
library(kableExtra)
```

```{=latex}
\begin{center}
\textit{\textbf{EvoCo}: Laboratorio de Evolución y Comportamiento Humano}, Facultad de Psicología, Universidad El Bosque, Bogotá, Colombia. Email: \href{mailto:jleongomez@unbosque.edu.co}{jleongomez@unbosque.edu.co}. Web: \href{https://jdleongomez.info/es}{jdleongomez.info}.

\vfill
\textbf{Resumen}
\end{center}

\par
\begingroup
\leftskip3em
\rightskip\leftskip
```

El meta-análisis es un método ampliamente utilizado para sintetizar los datos de diferentes estudios. Sin embargo, a menudo estudiantes, profesionales e investigadores carecemos de conocimientos prácticos para hacer e interpretar un meta-análisis. Esta guía presenta una batería de herramientas para realizar meta-análisis de correlaciones en R, ilustradas a partir de un ejemplo real. Incluye desde análisis simples y su interpretación hasta análisis con moderadores (meta-regresión), usando los paquetes [`metafor`](https://www.metafor-project.org/doku.php) [@viechtbauer2010] y [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) [@KossmeierMetaviz]. También incluye explicaciones para la transformación de coeficientes *r* de Pearson a *z* de Fisher (y viceversa), creación de gráficos de bosque (*forest plots*) y gráficos de embudo (*funnel plots*), análisis de heterogeneidad y diagnósticos de influencia, así como estrategias para detectar posibles sesgos de publicación utilizando el paquete [`weightr`](https://www.r-pkg.org/pkg/weightr) [@coburnWeightr2019], y para determinar el poder estadístico de un meta-análisis utilizando [`metameta`](https://www.dsquintana.blog/metameta-r-package-meta-analysis/) [@quintanaMetameta2022].

```{=latex}
\par
\endgroup

\par
\begingroup
\leftskip3em
\rightskip\leftskip
\footnotesize
```

[![Investigación Abierta](images%5CLogo-IA-Rectangulo.pdf)](https://www.youtube.com/@InvestigacionAbierta)

**Conocimientos necesarios:** Esta guía asume (1) un manejo básico de R, (2) comprensión de correlaciones y regresiones, y (3) un entendimiento de los principios del meta-análisis. De ser necesario, para adquirir la comprensión básica y necesaria del meta-análisis, recomiendo ver [este video](https://youtu.be/ntBbkOn9D_o) introductorio al meta-análisis en *jamovi* [@leongomezMetaanalysis2021] que publiqué en mi canal de YouTube [*Investigación Abierta*](https://www.youtube.com/@InvestigacionAbierta).

**Nota:** Está guía está inspirada en [este video](https://youtu.be/lH4VZMTEZSc) de @quintanaHowPerformMetaanalysis2021 y sus ejemplos, pero contiene pasos adicionales y alternativos, citas a fuentes primarias, e información complementaria más detallada. 

```{=latex}
\par
\endgroup
\vfill

\textbf{Cita esta guía como } \hrulefill 

\begin{hangparas}{.25in}{1}
Leongómez, J. D. (2022). Meta-análisis de correlaciones y meta-regresión en R: Guía práctica. \textit{Zenodo}. \url{https://doi.org/10.5281/zenodo.5640182}
\end{hangparas}
\newpage

{\hypersetup{hidelinks}
 \setcounter{tocdepth}{5}
 \tableofcontents
}
\newpage
```

# Base de datos de ejemplo

Para los ejemplos usados en ésta guía, usaré la base de datos `dat.molloy2014`, tomada de @molloy2013. Esta base de datos viene incluida con el paquete `metafor` de R.

Básicamente, @molloy2013 estudiaron si existe una asociación entre la concienciación (*conscientiousness*[^1]) y la adherencia a la medicación. En otras palabras, ¿las personas más *concienciadas* tienden a cumplir más con la medicación prescrita?

[^1]: Para una definición detallada del concepto de concienciación, ver @johnBigFiveTrait1999.

Primero, debemos cargar los principales paquetes que usaré a lo largo de esta guía: `metafor` [@viechtbauer2010] y `metaviz` [@KossmeierMetaviz] para hacer e ilustrar los resultados del meta-análisis, así como `dplyr` [@WickhamDplyr2021], `magrittr` [@magrittrcite] y `forecats` [@Wickhamforcats2022] para manipular y organizar la base de datos.

```{r eval = FALSE}
library(metafor)
library(metaviz)
library(dplyr)
library(magrittr)
library(forcats)
```

Como ya hemos cargado el paquete `metafor`, ya podemos cargar la base de datos `dat.molloy2014`. En éste caso, para poder *llamarla* cuando sea necesario, la asignaré a un objeto que llamaré simplemente `dat`.

```{r}
dat <- get(data(dat.molloy2014))
```

Tras asignar la base de datos a este objeto (`dat`), la base de datos se puede ver como *output*[^2] en la consola de R sencillamente usando como comando el nombre que le dimos al objeto al que lo asignamos (en este caso, `dat`).

[^2]: En R y otros lenguajes de programación, se llama "*output*" a la *salida* o resultado visible de una función o proceso, en este caso en la consola (que en RStudio es normalmente el panel que está a la izquierda en la parte inferior).

```{r}
dat
```

## Variables de la base de datos

Por favor mira la base de datos, y familiarízate con sus columnas. ¿Qué información contiene cada variable? Explicaré cada una a continuación.

Primero, hay unas columnas que contienen información absolutamente necesaria para poder hacer un meta-análisis: 

-   `authors`: los autores de cada estudio a meta-analizar

-   `year`: año de publicación de cada estudio

-   `ni`: tamaño de muestra de cada estudio

-   `ri`: coeficiente de correlación de Pearson de cada estudio

Esas son las variables más importantes y son necesarias para hacer un meta-análisis de correlación simple: alguna columna o columnas con información que permita identificar cada estudio (en este caso `authors` y `year`), una columna con el tamaño de muestra de cada estudio (en este caso, `ni`), y finalmente una columna con los coeficientes de correlación (en este caso la columna `ri`). Si tu meta-análisis no requiere moderadores, con una estructura como esta sería suficiente.

Después hay unas columnas que contienen variables específicas para este este ejemplo, y que son una serie de posibles moderadores que agrupan características de los estudios a meta-analizar:

-   `controls`: cantidad de variables controladas ("`none`": ninguna  o "`multiple`": múltiples)

-   `design`: si se utilizó un diseño transversal ("`cross-section`") o prospectivo ("`prospective`") [para más información acerca de estos tipos de diseño, ver por ejemplo @Manterola2019]

-   `a_measure`: tipo de medida de adherencia ("`self-report`": autoinforme u "`other`": otro tipo de medida más *objetivo*)

-   `c_measure`: tipo de medida de concienciación (si se midió con alguna versión del inventario de personalidad NEO o con alguna otra escala)

-   `meanage`: edad promedio de la muestra de cada estudio

-   `quality`: calidad metodológica (la calidad metodológica fue calificada por los autores del meta-análisis en una escala de 1 a 4, donde las puntuaciones más altas indican una mayor calidad; para información respecto a cómo se obtuvo esta puntuación, ver el artículo original de @molloy2013.

Por supuesto, el *output* de la consola no es la forma más clara de ver la base de datos, pero para una versión más legible, se puede usar la función `View`, y el nombre de la base de datos o tabla como argumento (en este caso `View(dat)`). Sin embargo, de aquí en adelante mostraré algunas tablas en un formato de impresión (y no como sale en la consola de R), para que sean más fáciles de leer.

Voy a volver a cargar la base de datos (sobrescribiendo el objeto `dat`), para organizarla un poco mejor. Primero, agregaré una nueva columna llamada `study_id`, en la que numeraré los estudios del 1 al 16, lo que será útil para identificar cada estudio en algunas gráficas y análisis. Después, reorganizaré las columnas para que `study_id` sea la primera, en vez de la última columna. Finalmente, las columnas de variables que son factores (`controls`, `design`, `a_measure`, `c_measure` y `quality`), pueden ser definidas como tal, para evitar pasos adicionales más adelante. En este caso, además, voy a reorganizar los niveles de la variable `controls` (primero `none` y después `multiple`); esto, aunque no es un paso necesario, puede ayudar con la interpretación de resultados.

```{r molloy2014}
dat <- get(data(dat.molloy2014)) %>%
  mutate(study_id = 1:16)  %>% # crear columna 'study_id' y agregar números del 1 al 16
  select(study_id, authors:quality) %>% # mover 'study_id' como primera columna
  mutate_at(c("controls", # transformar variables relevantes en factores
              "design",
              "a_measure",
              "c_measure",
              "quality"), 
            as.factor) %>% 
  mutate(controls = fct_relevel(controls, # reorganizar niveles de la variable 'controls'
                                "none", "multiple"))  
```

Con esto, la base de datos tiene ahora la siguiente estructura (Tabla \@ref(tab:estructuramod)):

```{r estructuramod, echo = FALSE, message = FALSE}
kable(dat, 
      linesep = "",
      booktabs = TRUE,
      caption = "Estructura de la base de datos con estudios numerados") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down")) %>% 
  footnote(general = "Datos tomados de Molloy et al. (2013).",
           general_title = "Nota:",
           footnote_as_chunk = TRUE)
```

# Preparación de los datos: transformación de coeficientes *r* de Pearson a *z* de Fisher

Los coeficientes de Pearson no se distribuyen normalmente, lo que podría llevar a calcular varianzas incorrectas, especialmente cuando se trata de correlaciones con tamaños de muestra pequeños. Por esto, lo mejor es transformar los coeficientes *r* de Pearson a *z* de Fisher [-@fisherFrequencyDistributionValues1915], que no tienen este problema[^3].

[^3]: Para decirlo de manera más precisa, el problema es que la distribución del coeficiente de correlación de Pearson (*r*), es muy sesgada cuando se trata de variables altamente correlacionadas (positiva, o negativamente). Esto dificulta la estimación de los intervalos de confianza y por tanto la aplicación de las pruebas de significación para coeficientes *r*. La transformación de Fisher de valores *r* a *z* ---que es la [tangente hiperbólica inversa](https://es.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica) de *r*--- resuelve este problema, pues los coeficientes *z* tienen una distribución aproximadamente normal, y una varianza estable a lo largo de diferentes valores posibles de *r* [para una demostración en español, ver @sanchez-brunoTransformacionFisherPara2005].

Para transformar los coeficientes *r* de Pearson a coeficientes *z* de Fisher, usaré la función `escalc` del paquete `metafor`, que sirve para calcular diversos tamaños de efecto que se utilizan comúnmente en meta-análisis. Los argumentos que requiere esta función, además del tipo de transformación a realizar (en este caso `measure = "ZCOR"`), son los coeficientes de correlación (`ri`), el tamaño de muestra de cada correlación (`ni`), y la base de datos que contiene estos valores (`data`). En nuestro caso, las columnas donde están estos valores, tienen los mismos nombres (`ri`, `ni`). En este ejemplo, asignaré el resultado de esta función al mismo objeto `dat`, que contiene la base de datos, para sobrescribirlo y no crear objetos adicionales.

```{r}
dat <- escalc(measure = "ZCOR", ri = ri, ni = ni, data = dat)
```

Esta función agrega dos nuevas variables: `yi`, que es el tamaño de efecto (en valores *z* de Fisher), y `vi` que es la varianza (Tabla \@ref(tab:estructuramod2)).

```{r estructuramod2, echo = FALSE, message = FALSE}
kable(dat, 
      linesep = "",
      booktabs = TRUE,
      caption = "Estructura de la base de datos, con transformación de los r de Pearon a z de Fisher") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down")) %>% 
  footnote(general = "Las nuevas columnas creadas usando la función \\\\texttt{escalc} 
           (\\\\texttt{yi} como tamaño de efecto y \\\\texttt{vi} como varianza) están 
           resaltadas en naranja",
           general_title = "Nota:",
           footnote_as_chunk = TRUE,
           escape = FALSE) %>% 
  column_spec(12:13, background = "#f68212")
```

# Hacer el meta-análisis {#meta-cor}

Para hacer el meta-análisis, usaré la función `rma` del paquete `metafor`. Esta función requiere especificar los tamaños de efecto (`yi`) y varianzas (`vi`) de los estudios a meta-analizar. En nuestro caso, las columnas donde están estos valores, tienen los mismos nombres (`yi`, `vi`). Asignaré los resultados del meta-análisis a un nuevo objeto llamado `res`.

```{r}
res <- rma(yi = yi, vi = vi, data = dat)
```

Los resultados, son los siguientes:

```{r}
res
```

## Interpretación de los resultados del meta-análisis {#meta-interp}

Vamos a analizar estos resultados de la consola de R por partes:

Primero, nos confirman que ajustamos un modelo con efectos aleatorios (`Random-Effects Model`), a partir de 16 estudios (`k = 16`), y que para estimar $\tau^2$ (tau cuadrado) usamos el método de **máxima verosimilitud restringida**[^4] (`tau^2 estimator: REML`), que se designa como *REML* por sus siglas en inglés .

[^4]: Hay varios métodos disponibles como estimador, además de **máxima verosimilitud restringida** (REML). Sin embargo, si tienes dudas, REML es una buena opción. Cada método tiene ventajas y desventajas que, si tienes interés en mirar, están descritas en la [documentación](https://www.rdocumentation.org/packages/metafor/versions/2.4-0/topics/rma.uni) de la función `rma`.

Posteriormente, nos provee los valores de una serie de estimadores de heterogeneidad:

-   $\tau^2$: `tau^2 (estimated amount of total heterogeneity): 0.0081 (SE = 0.0055)`

-   $\tau$: `tau (square root of estimated tau^2 value): 0.0901`

-   $I^2$: `I^2 (total heterogeneity / total variability): 61.73%`, y

-   $H^2$: `H^2 (total variability / sampling variability):  2.61`

La tercera parte, reporta otra prueba de heterogeneidad, usando el estadístico $Q$:

-   `Test for Heterogeneity:`

    `Q(df = 15) = 38.1595, p-val = 0.0009`

De todos estos, los más comúnmente reportados son $\tau^2$, $\tau$, $I^2$ y $Q$. Cada una de estas medidas tiene ventajas y desventajas, por lo cual tiene sentido reportarlas todas.

-   $I^2$: tiene la ventaja de ser sencillo de interpretar, pues hay criterios generales para heterogeneidad baja, moderada y alta (típicamente 25%, 50%, and 75%, respectivamente). Sin embargo, es muy sensible a los tamaños de muestra de los estudios meta-analizados (por ejemplo, si en tu meta-análisis hay estudios con tamaños de muestra muy grandes, esto va a sesgar tu $I^2$).

-   $Q$: aunque no es sensible al tamaño de muestra, es sensible al número de estudios meta-analizados. Tiene la ventaja de ser un test de hipótesis, y como tal, puede ser interpretado a partir de su valor *p*.

-   $\tau^2$: no tiene problemas de sensibilidad a los tamaños de muestra o número de estudios meta-analizados, pero es más difícil de interpretar. $\tau^2$ es una estimación de la varianza de los tamaños de los efectos reales entre los estudios meta-analizados. Se usa, principalmente, para asignar pesos a cada estudio [para más información, ver @borensteinIdentifyingQuantifyingHeterogeneity2009].

En nuestro caso, el estadístico $Q$ sugiere que hay una heterogeneidad significativa en los estudios meta-analizados ($p$ = 0.0009). $I^2$, sugiere una heterogeneidad moderada, lo que quiere decir que se estima que más de la mitad (61.73%) de la varianza se deriva de diferencias en los tamaños de efecto.

Más abajo, el *output* de la consola de R nos muestra los resultados de nuestro meta-análisis (`Model results`); en otras palabras, ¿cuál es el tamaño de efecto de la asociación entre concienciación (*conscientiousness*) y la adherencia a la medicación, según nuestro meta-análisis?

Esta parte nos provee varios resultados:

-   `Estimate (0.1499)`: estimado de la correlación entre concienciación y adherencia a la medicación, en este caso en valores *z* de Fisher, pues así transformamos los coeficientes de cada estudio

-   `se (0.0316)`: error estándar del estimado de la asociación (en valores *z* de Fisher)

-   `zval (4.7501)`: estadístico *Z* (mayúscula) que comprueba la media de una distribución. No se debe confundir con la transformación de coeficientes de correlación a *z* de Fisher (minúscula); este estadístico no nos provee una estimación de la asociación entre las variables correlacionadas, sino, de manera similar a una prueba *t*, nos sugiere si nuestra media (para el caso, el resultado de nuestro meta-análisis), se diferencia de 0 (o una correlación nula). Cuando *Z* es mayor a 1.96 (o menor a -1.96), nuestro resultado está en el 5% extremo de la distribución *Z* y sería significativo con un $\alpha$ tradicional de 0.05 (dos colas)

-   `pval (<.0001)`: valor *p* de la correlación meta-analizada

-   `ci.lb (0.0881)`: límite inferior del intervalo de confianza (*confidence interval lower bound*) de la correlación meta-analizada (en valores *z* de Fisher)

-   `ci.ub (0.2118)`: límite superior del intervalo de confianza (*confidence interval upper bound*) de la correlación meta-analizada (en valores *z* de Fisher)

-   Nivel de significación (`***`): representación con asteriscos (o un punto) del nivel de significación

-   `Signif. codes: 0 ’***’ 0.001 ’**’ 0.01 ’*’ 0.05 ’.’ 0.1 ’ ’ 1`: Clave para interpretar los niveles de significación. Aunque puede parecer complejo, básicamente, quiere decir que tres asteriscos (`***`) representan un valor *p* entre 0 y 0.001 (lo que comúnmente se representa como *p* \< .001); dos asteriscos (`**`) un valor *p* entre 0.001 y 0.01 (*p* \< .01); un asterisco (`*`) un valor *p* entre 0.01 y 0.05 (*p* \< .05); un punto (`.`) un valor *p* entre 0.05 y 0.01 (*p* \< .1, que ya no es significativo); y si no hay ningún símbolo, un valor *p* entre 0.1 y 1 (*p* > .1, no significativo)

En este caso, el meta-análisis nos sugiere que en efecto existe una asociación positiva entre concienciación y adherencia a la medicación (coeficiente de correlación transformado en *z* de Fisher = .1499), con un error estándar de 0.0316. Así mismo, sugiere que esa asociación es significativa (*Z* = 4.7501, $p$ < .0001), y nos muestra el intervalo de confianza del 95% (o IC 95%); los intervalos de confianza (en este caso del 95%) lo que estiman es que, si hiciéramos 100 muestras independientes, 95 de éstas contendrían una asociación que estaría entre los límites inferior (*z* = .0881) y superior (*z* = .2118) de estos intervalos de confianza.

Esto se podría resumir, por ejemplo, como:

> "**El meta-análisis sugiere que existe una asociación positiva entre concienciación y adherencia a la medicación (*z* ± *se* = 0.15 ± 0.032, IC 95% [0.09, 0.21]; *Z* = 4.75, $p$ < .0001). Hubo una heterogeneidad moderada significativa en torno al tamaño medio del efecto en los estudios meta-analizados ($\tau^2$ ± *se* =  0.0081 ± 0.0055; $\tau$ = 0.0901; $Q$(15) =  38.16, $p$ < .001; $I^2$ = 61.7%).**"

### Alternativa: Reportar el estimado como *r* de Pearson en vez de *z* de Fisher

Para reportar la correlación, si prefieres reportar coeficientes *r* de Pearson en vez de la transformación a *z* de Fisher, puedes transformar los valores *z* de Fisher de vuelta a *r* de Pearson. Para esto existen múltiples opciones en R, incluyendo simplemente usar la función `tanh`, que calcula la tangente hiperbólica, o la función `fisherz2r` del paquete `psych` [@revellePsych2021]. Por ejemplo, para transformar el estimado de nuestro meta-análisis a *r* de Pearson, sólo debo usar alguna de esas funciones, y agregar el valor *z* (0.1499 en nuestro caso) como único argumento:

```{r message = FALSE}
tanh(0.1499)
library(psych)
fisherz2r(0.1499)
```

Cualquiera de estas opciones nos da un valor de coeficiente de correlación de Pearson (*r* = 0.1487872), muy similar al obtenido como *z* de Fisher (*z* = 0.1499). Esto se debe a que, para coeficientes *r* de Pearson entre -0.4 y 0.4, la transformación a valores *z* de Fisher produce resultados muy similares (Fig. \@ref(fig:rvsz)). 

```{r rvsz, echo = FALSE, message = FALSE, warning = FALSE, fig.height = 4, fig.cap = "Asociación entre coeficientes de correlación *r* de Pearson (eje *X*), y su transformación a *z* de Fisher (eje *Y*). La línea naranja representa la asociación entre valores *r* y *z*; como referencia, la línea negra punteada representa igualdad entre ejes (*y* = *x*). Como se puede ver, cuando *r* está aproximadamente entre -0.4 y 0.4 (rectángulo gris), los valores *r* y *z* son casi idénticos. Para valores más extremos, el valor de *z* se aleja progresivamente del valor de *r*."}

library(tidyquant)

rVsz <- tibble(r = c(seq(-0.999, -0.901, by = 0.001), 
                     seq(-0.9, 0.9, by = 0.01), 
                     seq(0.901, 0.999, by = 0.001))) %>%
  mutate(z = atanh(r))
  
ggplot(rVsz, aes(x = r, y = z)) +
  annotate("rect", xmin = -0.4, xmax = 0.4, ymin = -Inf, ymax = Inf, alpha = 0.2) +
  annotate("text", x = 0, y = 0.2, 
                label = expression(paste("Mínima diferencia entre ", italic(r)," y ", italic(z))), 
           parse = TRUE,
           angle = 16,
           size = 2) +
  geom_smooth(se = FALSE, color = "#F68212") +
  geom_segment(aes(x = -1, xend = 1, y = -1, yend = 1), lty = "dotted", alpha = 0.1) +
  xlim(-1, 1) +
  scale_x_continuous(breaks = round(seq(-1, 1, by = 0.1),1)) +
  scale_y_continuous(breaks = round(seq(-3, 3, by = 0.2),1)) +
  labs(x =  expression(paste("Coeficiente de correlación (", italic("r"), ") de Pearson")),
       y = expression(paste("Transformación a ", italic(" z"), " de Fisher"))) +
  theme_tq()
```

Por supuesto, si decides reportar los resultados de tu meta-análisis en coeficientes *r* de Pearson, siempre puedes hacer lo mismo con el error estándar y los límites del intervalo de confianza del 95% (todos valores en *z* de Fisher, pues fue el tamaño de efecto que meta-analizamos).

## Más información sobre heterogeneidad

Es importante tener en cuenta que la heterogeneidad no es un *supuesto* que se deba cumplir al hacer un meta-análisis, y por ende una heterogeneidad moderada o alta no invalida sus resultados. Sencillamente es información útil que se debe reportar y tener en cuenta al interpretar el resultado de un meta-análisis. En este caso, la presencia de heterogeneidad sugiere que los estudios meta-analizados varían y no suelen reportar resultados similares.

De manera general, y para decirlo de manera más técnica, la presencia de heterogeneidad estadística es indicativa de una variación entre los estudios en la magnitud y la dirección de la estimación del efecto estudiado [para más información y ejemplos, ver @sedgwickMetaanalysesWhatHeterogeneity2015]. 

Por esto, reportar información detallada acerca de la heterogeneidad de los estudios meta-analizados es siempre útil. De hecho, además de reportar los estadísticos $\tau^2$, $\tau$, $I^2$ y $Q$ (como expliqué en la sección \@ref(meta-interp)), podemos fácilmente calcular los intervalos de confianza para $\tau^2$, $\tau$, e $I^2$ (además de $H^2$, que no he usado) con la función `confint`.

```{r}
confint(res)
```

Para $\tau^2$, el hecho de que los límites del intervalo de confianza no crucen el 0 (es decir, no hay un límite negativo y otro positivo; en nuestro caso, ambos son positivos:  IC 95% [0.0017, 0.0378]), también sugiere que que hay heterogeneidad entre los estudios que meta-analizamos.

Estos intervalos de confianza que también pueden ser reportados junto a sus correspondientes  estadísticos. Entonces, esto se podría resumir, por ejemplo, como:

> "**El meta-análisis sugiere que existe una asociación positiva entre concienciación y adherencia a la medicación (*z* ± *se* = 0.15 ± 0.032, IC 95% [0.09, 0.21]; *Z* = 4.75, $p$ < .0001). Hubo una heterogeneidad moderada significativa en torno al tamaño medio del efecto en los estudios meta-analizados ($\tau^2$ ± *se* =  0.0081 ± 0.0055, IC 95% [0.0017, 0.0378]; $\tau$ = 0.0901, IC 95% [0.0412, 0.1944]; $Q$(15) =  38.16, $p$ < .001; $I^2$ = 61.7%, IC 95% [25.2799%, 88.2545%]).**"

## Diagnóstico de influencia {#diag-inf}

Otro aspecto importante de un meta-análisis, es determinar si alguno o algunos de los estudios meta-analizados es o son particularmente influyentes en nuestro resultado[^5]. Para esto, se suele usar la técnica conocida como *leave-one-out*, que se refiere al resultado del meta-análisis cuando se excluye cada estudio; al estimar cómo y cuánto cambia el resultado del modelo de meta-análisis al excluir cada estudio, podemos estimar su influencia en el resultado. Dicho de otra manera, si al excluir un estudio el resultado cambia mucho, sabemos que ese estudio tiene gran influencia en el meta-análisis y sería mejor excluirlo. 

Para hacer un análisis de influencia, podemos usar la función `influence` del paquete `metafor`, cuyo resultado, en este caso, asignaré a un objeto llamado `inf.res`.

[^5]: Por ejemplo, si estuviésemos meta-analizando 20 estudios, de los cuales 19 tienen un *n* de 100, pero el otro tiene un *n* de 10.000, éste último tendrá una influencia enorme en nuestro resultado. Sería preocupante que nuestro meta-análisis sea dependiente principalmente de un único estudio.

```{r}
inf.res <- influence(res)
```

Dado que lo asigné a un objeto (`inf.res`), para ver el resultado, debo usar como comando el nombre que le di al objeto.

```{r}
inf.res
```

Esto me muestra gran cantidad de datos de cada estudio (en este caso, lo presento como una tabla sin formato, tal cual se ve en la consola de R), y contiene información que puede parecer muy compleja; sin embargo, como verás, la última columna resume la interpretación general de estos resultados de influencia, facilitando muchísimo su interpretación. 

Las columnas que incluye son:

-   `rstudent`: residuos estandarizados externamente. Esto **no** corresponde al coeficiente de correlación de cada estudio, sino a la diferencia entre el tamaño de efecto observado en cada estudio, y la predicción de dicho valor cuando dicho estudio se elimina del meta-análisis

-   `dffits`: diferencia de ajuste(s) (en inglés *difference in fit(s)*). Es una medida diagnóstica de la influencia de cada punto en una regresión (en este caso, cada estudio en un meta-análisis) propuesta originalmente por @belsleyRegressionDiagnosticsIdentifying1980

-   `cook.d`: Distancia de Cook (en inglés, *Cook's distance*). Es otra medida diagnóstica de la influencia, propuesta originalmente por @cookDetectionInfluentialObservation1977. Es conceptualmente idéntica a DFFITS (`dffits`), y de hecho existe una fórmula para convertir una medida en la otra [@Henry2003]. Aunque no hay un acuerdo absoluto al respecto, comúnmente se asume que valores mayores a 1 ($D_{i} > 1$), representan puntos (o, en este caso, estudios) influyentes en un modelo [@cookResidualsInfluenceRegression1982], que probablemente deban ser excluidos

-   `cov.r`: relación (o proporción) de covarianza. Es el determinante de la matriz de varianza-covarianza de las estimaciones de los parámetros basadas en el conjunto de datos, cuando cada estudio se elimina del meta-análisis, dividido por el mismo determinante de la matriz de varianza-covarianza cuando se incluyen todos los estudios. Sé que suena complejo, pero básicamente, un valor menor a 1 indica que la eliminación de ese estudio produce estimaciones más precisas de los coeficientes del modelo

-   `tau2.del`: es la heterogeneidad (residual) $\tau^2$ cuando se elimina cada estudio

-   `QE.del`: similar al resultado anterior, este se refiere al estadístico $Q$ obtenido cuando se excluye cada estudio

-   `hat`: los valores *hat* ($h$) son una medida estandarizada de la distancia de cada punto a la media de la variable predictora. Mientras valores cercanos a 0 indican que no hay un valor preocupante, valores cercanos a 1, aunque no indican directamente alta influencia de algún punto, ciertamente nos indican que vale la pena investigar más. Los valores *hat* están abiertos a la interpretación, pero un valor de corte que es común es el doble de la media de los todos valores *hat* ($\overline{h}$); cualquier estudio con un valor mayor debe ser examinado con cuidado

-   `weight`: peso asignado a cada estudio

-   `dfbs`: el valor de `dfbs` (o *DFBETAS*) indica cuántas desviaciones estándar cambia el coeficiente estimado después de excluir cada estudio del modelo de meta-análisis 

-   `inf`: por suerte, esta columna `inf` resume esta información por nosotros. Cualquier estudio que se considere influyente, teniendo en cuenta la diferencia de ajuste, la distancia de Cook, los valores *hat* o *DFBETAS*, será señalado acá como influyente, usando asteriscos

Aunque hay mucha información, lo más importante ahora es mirar la última columna, llamada `inf`. Si ahí aparecieran asteriscos para algún estudio meta-analizado (que no es nuestro caso), sugeriría que ese estudio es particularmente influyente y podría ser necesario eliminarlo del meta-análisis.

Por último, podemos también ver ésta información que tenemos guardada en el objeto `inf.res`, de manera gráfica, usando la función `plot` (Fig. \@ref(fig:infplot)).

```{r infplot, fig.height = 7, fig.cap = "Diagnóstico de influencia. Estudios particularmente influyentes serían representados con un punto rojo. Los números 1 a 16 en el eje *X* representan cada estudio, como lo definimos en columna \\texttt{study\\_id} de la Tabla \\@ref(tab:estructuramod). En este caso, no hay ningún estudio que se considere demasiado influyente, por lo éste análisis sugiere que no es necesario excluir ningún estudio de nuestro meta-análisis."}
plot(inf.res)
```

## *Forest plot* (diagrama de bosque)

Hacer un diagrama de bosque (*forest plot*) que resuma nuestro meta-análisis usando  [`metafor`](https://www.metafor-project.org/doku.php) es muy fácil; sólo tenemos que usar la función `forest`, usando como argumento el objeto al que asignamos los resultados de nuestro meta-análisis (en nuestro caso, `res`).

```{r eval = FALSE}
forest(res)
```

Esto produce la Fig. \@ref(fig:for-plot1).

```{r for-plot1, echo = FALSE, fig.height = 5.5, fig.cap = "*Forest plot* básico de [metafor](https://www.metafor-project.org/doku.php). Para cada estudio meta-analizado, tenemos el efecto (correlación, en este caso en valores *z* de Fisher), así como sus intervalos de confianza entre paréntesis cuadrados. Esta misma información está representada gráficamente, con los cuadrados representando el efecto de cada estudio así como sus intervalos de confianza como barras de error, y el tamaño de muestra representado por el tamaño del cuadrado. Bajo estos resultados, tenemos nuestro meta-análisis, con el mismo formato en texto, pero representando el efecto y sus intervalos de confianza con un diamante."}
par(mar = c(4,0,0,0))
forest(res)
```

Como se puede ver en las Figuras \@ref(fig:for-plot1), \@ref(fig:for-plot2) y \@ref(fig:for-plot3b) (que son versiones del mismo *forest plot*), no es una sorpresa que el análisis nos sugiera bastante heterogeneidad; las correlaciones encontradas entre los diferentes estudios varían mucho (están entre `r min(dat$ri)` y `r max(dat$ri)`), y aunque son positivas en la mayoría de los casos, en algunos son prácticamente 0 o incluso negativas.

Para una versión más completa y anotada, también usando el *plot* básico de [`metafor`](https://www.metafor-project.org/doku.php), pero agregando encabezados de cada columna en español, nombres de los estudios meta-analizados[^6] así como una columna con los pesos dados a cada estudio, y detalles del modelo final[^7], podemos hacer algo como esto:

[^6]: En este caso, dado que tenemos los autores y los años de publicación de cada estudio en columnas separadas, pegué las columnas `authors` y `year` separadas por una coma y un espacio: `paste(dat$authors, dat$year, sep = ", ")` como argumento `slab`.

[^7]: Estas opciones están explicadas [acá](https://search.r-project.org/CRAN/refmans/metafor/html/forest.rma.html).

```{r eval = FALSE}
# forest plot con anotaciones adicionales
forest(res, cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L),
       mlab = bquote(paste("Modelo EA: Q(", .(res$k - res$p), ") = ",
     .(formatC(res$QE, digits = 2, format = "f")),
     ", p ", .(scales::pvalue(res$pval)), "; ", I^2, " = ",
     .(formatC(res$I2, digits = 1, format = "f")), "%")))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
op <- par(cex = 0.8, font = 2) 
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

```{r for-plot2, echo = FALSE, fig.height = 5, fig.cap = "*Forest plot* anotado, creado con [metafor](https://www.metafor-project.org/doku.php). En esta versión agregué algunos encabezados en español, así como estadísticos generales del modelo de meta-análisis. Modelo EA se refiere al modelo meta-analizado, de efectos aleatorios."}
# forest plot con anotaciones adicionales
par(mar = c(4,0,0,0))
forest(res, cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L),
       mlab = bquote(paste("Modelo EA: Q(", .(res$k - res$p), ") = ",
     .(formatC(res$QE, digits = 2, format = "f")),
     ", p ", .(scales::pvalue(res$pval)), "; ", I^2, " = ",
     .(formatC(res$I2, digits = 1, format = "f")), "%")))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
op <- par(cex = 0.8, font = 2) 
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

O, para un *forest plot* quizás más sofisticado, se puede usar la función [`viz_forest`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#creating-forest-plots-with-function-viz_forest) del paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html).

```{r eval = FALSE}
# A. Variante "classic" (no tiene que ser definida, pues es la opción por defecto)
viz_forest(res, 
           study_labels = paste(dat$authors, dat$year, sep = ", "),
           xlab = "Correlación", 
           annotate_CI = TRUE,
           summary_label = "Resumen",
           text_size = 2.6,
           x_trans_function = tanh)

# B. Variante "thick"
viz_forest(res, 
           study_labels = paste(dat$authors, dat$year, sep = ", "),
           xlab = "Correlación", 
           variant = "thick",
           col = "Greens",
           annotate_CI = TRUE,
           summary_label = "Resumen",
           text_size = 2.6,
           x_trans_function = tanh)

# C. Variante "rain"
viz_forest(res, 
           study_labels = paste(dat$authors, dat$year, sep = ", "),
           xlab = "Correlación", 
           variant = "rain",
           col = "Oranges",
           annotate_CI = TRUE,
           summary_label = "Resumen",
           text_size = 2.6,
           x_trans_function = tanh)
```

Con el código anterior genero las siguientes tres versiones del mismo *forest plot* (Fig. \@ref(fig:for-plot3b)) usando diferentes variantes y escalas de colores, y transformando de vuelta los coeficientes de *z* de Fisher a *r* de Pearson (con el argumento `x_trans_function = tanh`).

Por supuesto, es cuestión de gusto cuál usar.

```{r for-plot3, echo = FALSE, fig.height = 3}
library(metaviz)
p.classic <- viz_forest(res, 
                        study_labels = paste(dat$authors, dat$year, sep = ", "),
                        xlab = "Correlación", 
                        annotate_CI = TRUE,
                        summary_label = "Resumen",
                        text_size = 2.6,
                        x_trans_function = tanh)

ggarrange(p.classic,
          labels = c("A"))
```

```{r for-plot3b, echo = FALSE, fig.height = 6, warning = FALSE, fig.cap = 'Variantes de *forest plots* creados con  [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html). **A.** Variante clásica (opción por defecto). **B.** Variante "thick" y escala de colores "Greens". **C.** Variante "rain" y escala de colores "Oranges".'}
p.thick <- viz_forest(res, 
                      study_labels = paste(dat$authors, dat$year, sep = ", "),
                      xlab = "Correlación", 
                      variant = "thick",
                      col = "Greens",
                      annotate_CI = TRUE,
                      summary_label = "Resumen",
                      text_size = 2.6,
                      x_trans_function = tanh)

p.rain <- viz_forest(res,
                     study_labels = paste(dat$authors, dat$year, sep = ", "),
                     xlab = "Correlación", 
                     variant = "rain",
                     col = "Oranges",
                     annotate_CI = TRUE,
                     summary_label = "Resumen",
                     text_size = 2.6,
                     x_trans_function = tanh)

ggarrange(p.thick, p.rain,
          labels = c("B", "C"),
          nrow = 2)
```

## *Funnel plot* (diagrama de embudo), regresión de Egger y sesgo de estudios pequeños

La creación e interpretación del *Funnel plot* es crucial, y aporta información muy importante acerca de un meta-análisis. Sin embargo, es en donde más errores se cometen. 

### Errores en la interpretación del *Funnel plot* y la regresión de Egger {#err-funnel-egger}

El principal error que la mayoría de los investigadores podemos cometer[^8], es concluir que un meta-análisis tiene (o no) riesgo de sufrir de sesgos de publicación, simplemente basándonos en la evaluación de la asimetría en el *funnel plot* y la regresión de Egger [@eggerBiasMetaanalysisDetected1997] (sección \@ref(reg-egger)).

Estos métodos, sin embargo, no son pruebas exclusivas de sesgo de publicación, sino de sesgo de estudios de tamaño muestral pequeño [ver e.g. @schwarzerSmallStudyEffectsMetaAnalysis2015], que pueden incluir sesgo de publicación, pero no se centran exclusivamente en esto (explico algunas técnicas específicas para estimar el sesgo de publicación en la sección \@ref(sesgo-pub)).

[^8]: Me incluyo pues por supuesto también soy culpable de haber cometido este error en el pasado, incluyendo algunas ideas que expuse en mi video sobre meta-análisis en *jamovi* [@leongomezMetaanalysis2021].

A pesar de esto, tanto la regresión de Egger como el *funnel plot* son interesantes, pues es importante considerar el sesgo que podrían generar estudios con tamaño de muestra pequeño en nuestra estimación del efecto *real* (o, para decirlo más técnicamente, el sesgo que podrían introducir estudios con poder estadístico bajo).

### *Funnel plot*

Para crear un *funnel plot* de nuestro meta-análisis con [`metafor`](https://www.metafor-project.org/doku.php) sólo tenemos que usar la función `funnel`, usando como argumento el objeto al que asignamos los resultados de nuestro meta-análisis (`res`). Con esto, generamos la Figura \@ref(fig:funnel-plot1).

```{r eval = FALSE}
funnel(res)
```

```{r funnel-plot1, echo = FALSE, fig.height = 5, fig.cap = "*Funnel plot* básico de [metafor](https://www.metafor-project.org/doku.php). Para cada estudio meta-analizado, tenemos el efecto (correlación, en este caso en valores *z* de Fisher) en el eje *X*, así como su error estándar en el eje *Y*. La línea punteada vertical representa el efecto *real* estimado mediante nuestro meta-análisis (*z* = 0.15), así que podemos ver los estudios que encontraron un efecto mayor (derecha) o menor (izquierda) que éste. A primera vista no parece haber mucha asimetría, pero es importante tener en cuenta que es un análisis muy subjetivo."}
par(mar = c(4,4,0,1))
funnel(res)
```

O, si queremos cambiar los títulos de los ejes, por ejemplo escribiéndolos en español, podemos hacerlo agregando los argumentos `xlab` (para el eje $X$) y/o `ylab` (para el eje $Y$), como se ve en la Figura \@ref(fig:funnel-plot1a).

```{r eval = FALSE}
funnel(res, 
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       ylab = "Error estándar")
```

```{r funnel-plot1a, echo = FALSE, fig.height = 5, fig.cap = "*Funnel plot* básico de [metafor](https://www.metafor-project.org/doku.php), con títulos de ejes en español. Para cada estudio meta-analizado, tenemos el efecto (correlación, en este caso en valores *z* de Fisher) en el eje *X*, así como su error estándar en el eje *Y*. La línea punteada vertical representa el efecto *real* estimado mediante nuestro meta-análisis (*z* = 0.15), así que podemos ver los estudios que encontraron un efecto mayor (derecha) o menor (izquierda) que éste."}
par(mar = c(4,4,0,1))
funnel(res, 
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       ylab = "Error estándar")
```

De nuevo, para una versión más sofisticada, se puede usar el paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html), usando la función [`viz_funnel`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#creating-funnel-plots-with-viz_funnel). Hay muchas opciones, pero como ejemplo, usaré la versión por defecto, agregando sólo la línea de la regresión de Egger (`egger = TRUE`; ver sección \@ref(reg-egger), más adelante), transformando los tamaños de efecto de regreso a $r$ de Pearson (`x_trans_function = tanh`), y con los títulos de los ejes en español (Fig. \@ref(fig:funnel-plot2)).

```{r funnel-plot2, fig.height = 4.5, warning = FALSE, fig.cap = "*Funnel plot* creado con [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html). En azul, se representa el área donde estudios, según su error (y su tamaño de muestra), tendrían un efecto significativo al 5% (i.e. $p$ < 0.05), y fuera de ésta, donde tendrían un efecto significativo al 1% (i.e. $p$ < 0.01). La línea negra vertical representa el efecto meta-analizado, y el triángulo a partir de su inicio, el área donde se ubican los estudios que no se diferencian significativamente del resultado del meta-análisis. La línea roja punteada, representa la regresión de Egger."}
viz_funnel(res, 
           egger = TRUE,
           x_trans_function = tanh,
           ylab = "Error estándar",
           xlab = "Coeficiente de correlación")
```

Alternativamente, el paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) tiene la función [`viz_sunset`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#sunset-power-enhanced-funnel-plots), que permite además mostrar el poder estadístico (o potencia) de los estudios meta-analizados para detectar un efecto de interés mediante una prueba de Wald de dos colas. De ser necesario, para entender las bases del poder estadístico, recomiendo ver [esta serie de videos](https://youtube.com/playlist?list = PLHk7UNt35ccVdyHqnQ6oXVYA6JBNFrE1x) [@leongomezPoderRvid2020] y/o, para mayor profundidad, leer [esta guía](https://doi.org/10.5281/zenodo.3988776) [@leongomezAnalisisPoderEstadistico2020] que publiqué anteriormente.

A continuación, muestro dos versiones de *funnel plots* creados con la función `viz_sunset` (Fig. \@ref(fig:funnel-plot3)). En ambos casos, agregué el efecto *real* estimado a partir del meta-análisis (`contours = TRUE`), y transformé los tamaños de efecto de regreso a $r$ de Pearson (`x_trans_function = tanh`).

```{r eval = FALSE}
# A. Escala de poder discreta
viz_sunset(res,
           contours = TRUE,
           x_trans_function = tanh)

# B. Escala de poder contínua
viz_sunset(res, 
           contours = TRUE,
           x_trans_function = tanh, 
           power_contours = "continuous")
```

```{r funnel-plot3, message = TRUE, echo = FALSE, fig.height = 8.5, fig.width = 6, warning = FALSE, fig.cap = "Dos versiones de *funnel plot* creados con [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html), usando la función viz-sunset, que estima el poder de cada estudio para detectar un efecto de interés. **A.** Poder representado por bandas dicretas de color. **B.** Poder representado de manera contínua en una escala de color. En ambos casos, y tal como en la Fig. \\@ref(fig:funnel-plot2), el efecto real está representado como una línea vertical, y el triángulo a partir de su inicio representa el área donde se ubican los estudios que no se diferencian significativamente del resultado del meta-análisis."}
p.suna <- viz_sunset(res, 
                     contours = TRUE,
                     x_trans_function = tanh)
p.sunb <- viz_sunset(res, 
                     contours = TRUE,
                     x_trans_function = tanh,
                     power_contours = "continuous")
  
ggarrange(p.suna, p.sunb,
          labels = "AUTO",
          nrow = 2)
```

### Regresión de Egger {#reg-egger}

Para hacer una prueba formal de sesgo de estudios pequeños [@sternePublicationRelatedBias2000; @schwarzerSmallStudyEffectsMetaAnalysis2015], a partir de la asimetría en el *funnel plot*, podemos hacer una prueba o regresión de Egger [@eggerBiasMetaanalysisDetected1997]. En [`metafor`](https://www.metafor-project.org/doku.php), esto se hace con la función `regtest`, de nuevo usando como argumento el objeto al que asignamos el resultado de nuestro meta-análisis (`res`).

```{r eval = FALSE}
regtest(res)
```

Como se puede ver, en este caso la prueba de Egger no muestra un resultado significativo (`Test for Funnel Plot Asymmetry: z = 1.0216, p = 0.3070`), lo que sugiere que no hay sesgo de estudios pequeños.

```{r echo = FALSE}
regtest(res)
```

Con base en esto, y la inspección visual subjetiva del *funnel plot*, muchos investigadores podrían concluir, sin sustento adecuado, que en nuestro meta-análisis no hay sesgo de publicación. Sin embargo, como mencioné antes (sección \@ref(err-funnel-egger)), estas pruebas no se centran en el sesgo de publicación sino en el sesgo de estudios pequeños. En otras palabras, con base en esto, lo único que podemos concluir correctamente, es que no hay sesgo de estudios pequeños (en la sección \@ref(sesgo-pub) a continuación, explicaré cómo evaluar si hay sesgo de publicación).

## Sesgo de publicación (*publication bias*) {#sesgo-pub}

Existen diferentes opciones para estimar el sesgo de publicación de un meta-análisis. En esta sección, me centraré en dos: primero, el método de recorte y relleno (*trim and fill*; sección \@ref(trim-fill)); y segundo, el modelo de función de peso de Vevea y Hedges (sección \@ref(vevea-hedges)), que es uno de los modelos de selección más conocidos para la evaluación del sesgo de publicación.

### Método *trim and fill* (recorte y relleno) {#trim-fill}

El método de recorte y relleno (*trim and fill*) es una técnica no paramétrica para aumentar datos [@duvalNonparametricTrimFill2000; @duvalTrimFillSimple2000; ver también @duvalTrimFillMethod2005]. Este método puede utilizarse para ajustar el número y los resultados de los estudios que se estima faltan en un meta-análisis, con base en el escrutinio de un lado de un diagrama de embudo (*funnel plot*), para evaluar la asimetría que se supone que se debe al sesgo de publicación. 

Básicamente, el método aumenta los estudios observados para que el gráfico de embudo sea más simétrico, y vuelve a calcular la estimación del meta-análisis con base en los datos completos. 

Aunque muy útil, es importante tener en cuenta que método de recorte y relleno (*trim and fill*) tiene algunas limitaciones que siempre deben considerarse:

-  No debe ente derse como una forma de obtener una estimación más "válida" del efecto *real*, sino como una forma de examinar qué tan sensibles son los resultados a un mecanismo de selección particular (es decir, una forma particular de sesgo de publicación)

-  Es importante tener en cuenta que este método no se puede usar en modelos con moderadores, como los que explico en la sección \@ref(met-moderation)

En [`metafor`](https://www.metafor-project.org/doku.php), el método de recorte y relleno (*trim and fill*) se hace simplemente con la función `trimfill`, de nuevo usando como argumento el objeto al que asignamos el resultado de nuestro meta-análisis (`res`). En este caso, asignaré el resultado de esta función a un objeto que llamaré `tf`.

```{r}
tf <- trimfill(res)
tf
```

Esto nos muestra unos resultados equivalentes y muy similares a los de nuestro meta-análisis original (sección \@ref(meta-cor)) y que se deben interpretar de manera igual. 

Sin embargo, hay unos pequeños cambios. Primero, comienza diciendo que el número estimado de estudios que faltan en el lado izquierdo es 2 (`Estimated number of missing studies on the left side: 2 (SE = 2.7118)`), lo que quiere decir que estimó que faltaban dos estudios al lado izquierdo de nuestro *funnel plot*, y no se recortó ninguno. Por supuesto, al sumar estos dos estudios hipotéticos, el meta-análisis se hace con base en *k* = 18 estudios, en vez de 16 (`Random-Effects Model (k = 18; tau^2 estimator: REML)`).

 Como los dos estudios hipotéticos que se agregaron están a la izquierda de nuestro *funnel plot*, tienen un tamaño de efecto menor al efecto *real* que estimamos inicialmente de *z* = 0.15. Esto por supuesto hace que el efecto que estimamos usando el método *trim and fill* sea menor (*z* = 0.13, como se ve en los resultados de nuestro meta-análisis (`Model results`: `Estimate (0.1288)`).

Para crear ver esto gráficamente, podemos hacer un *funnel plot* del meta-análisis con el método de recorte y relleno (*trim and fill*) usando [`metafor`](https://www.metafor-project.org/doku.php). Sólo tenemos que usar la función `funnel`, usando
como argumento el objeto al que asignamos los resultados del método de recorte y relleno (`tf`). Con esto, generamos la Figura \@ref(fig:tf-plot1).

```{r tf-plot1, fig.cap = "*Funnel plot* básico de [metafor](https://www.metafor-project.org/doku.php) usando el método de recorte y relleno (*trim and fill*). En negro los estudios meta-analizados; en blanco, los estudios *rellenados*."}
funnel(tf, 
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       ylab = "Error estándar")
```

De nuevo, alternativamente podemos usar la función `viz_funnel` del paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html), para crear este *funnel plot* representando los estudios *rellenados* con el método de recorte y relleno. Sin embargo, para esto usaremos como argumento el meta-análisis original (`res`), pero agregando los argumentos `trim_and_fill = TRUE` y `trim_and_fill_side = "left"` ("left" dado que sabemos que los estudios *faltantes* están a la izquierda del *funnel plot*). 

```{r tf-plot2, fig.cap = "*Funnel plot* creado con [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) usando el método de recorte y relleno (*trim and fill*). En blanco los estudios meta-analizados; en negro, los estudios *rellenados*."}
viz_funnel(res, 
           contours_col = "Oranges",
           trim_and_fill = TRUE, 
           trim_and_fill_side = "left", #IMPORTANTE
           egger = TRUE,
           x_trans_function = tanh,
           ylab = "Error estándar",
           xlab = "Coeficiente de correlación") +
  geom_vline(xintercept = 0, linetype = "dotted")
```

El resultado nos muestra que el análisis aumentó dos estudios hipotéticos a la izquierda. Es decir, sugiere que hay *cierto* nivel de sesgo de publicación. De hecho, la estimación del efecto al aumentar estos estudios hipotéticos para que la distribución sea realmente simétrica, disminuye a 0.1288, algo menor que el 0.1499 que nos sugería el análisis inicial. 

Si quieres profundizar en el método de recorte y relleno (*trim and fill*), su interpretación, así como sus fortalezas y limitaciones, te recomiendo leer el artículo de @shiTrimandfill2019 al respecto.

### Modelo de función de peso de Vevea y Hedges {#vevea-hedges}

El modelo de función de peso de Vevea y Hedges [@veveaGeneralLinearModel1995; @veveaPublicationBiasResearch2005] es uno de los modelos se selección (en inglés, *selection models*) más conocidos[^9].

[^9]: El otro modelo de selección muy conocido, es el modelo de Copas y Shi [-@copasMetaanalysisFunnelPlots2000; -@copasSensitivityAnalysisPublication2001]. Aunque no lo incluyo en ésta guía, es importante mencionar que hay evidencia que muestra que es preferible a métodos como el de *trim and fill* [@schwarzerEmpiricalEvaluationSuggests2010]. En R, éste método se puede implementar con la función `copas` del paquete `metasens` [@schwarzerMetasensPackage; ver también Capítulo 5 en @schwarzerMetaAnalysis2015].

Los modelos de selección intentan describir el mecanismo de supresión del efecto y combinarlo con un modelo de tamaño del efecto que describa la distribución de los efectos en ausencia de sesgo de publicación.

El modelo de Vevea y Hedges da más peso a ciertos tamaños de efecto. La realidad de la literatura científica es que es más probable que algunos estudios sean publicados, dependiendo de sus valores $p$ [@coburnPublicationBiasFunction2015; para una descripción sencilla y general, ver por ejemplo @SesgoPublicacion2008]. En particular, es más probable que sean publicados los estudios con resultados *significativo* (típicamente, $p < 0.05$, usando un $\alpha$ tradicional de 0.05), en comparación con estudios con resultados no significativos (es decir, con resultados que no permiten rechazar la hipótesis nula). Estos sesgos pueden por supuesto sesgar la literatura publicada, y afectar nuestro meta-análisis.

En R, para estimar el sesgo de publicación de un meta-análisis usando el modelo de función de peso de Vevea y Hedges, se puede usar la función `weightfunct` del paquete `weightr` [@coburnWeightr2019].

Esta función que nos permite "estimar tanto el modelo de función de peso para el sesgo de publicación que se publicó originalmente en @veveaGeneralLinearModel1995 como la versión modificada presentada en @veveaPublicationBiasResearch2005", como se describe en la [documentación](https://www.rdocumentation.org/packages/weightr/versions/2.0.2/topics/weightfunct) de la función `weightfunct`.

```{r message = FALSE}
library(weightr)
```

En este caso, usaré esta función, asignando el resultado a un objeto que llamaré `wf`.

```{r}
wf <- weightfunct(effect = dat$yi, v = dat$vi, table = TRUE)
wf
```

Los resultados tienen una estructura similar a los del meta-análisis original (descrito y explicado en la sección \@ref(meta-cor)) y a los del meta-análisis usando el método *trim and fill* (sección \@ref(trim-fill)). Sin embargo, se organizan en dos partes; primero presenta los resultados del modelo no ajustado (bajo el encabezado `Unadjusted Model (k = 16)`), y después presenta los resultados del modelo con pesos ajustados de acuerdo al modelo de función de peso de Vevea y Hedges (bajo el encabezado `Adjusted Model (k = 16)`).

El modelo no ajustado nos da un estimado muy similar (pero no idéntico) al del estudio original (0.1486), dado que usa un método ligeramente diferente.

Como antes, también nos da valores de heterogeneidad $\tau^2$, $\tau$ y $Q$.

Pero lo más importante, es que en la segunda parte (el modelo ajustado) los resultado del meta-análisis se calculan de acuerdo con los pesos dados a cada efecto. 

Esta técnica, a diferencia del método *trim and fill* no "recorta" ni "rellena" estudios, por lo que el análisis se hace con el mismo número de estudios (en este caso, 16; por eso en encabezado dice `Adjusted Model (k = 16)`).

Sin embargo, la función `weightfunct` incrementa el peso de estudios que tienen menos probabilidad de ser publicados (típicamente resultados no significativos), y reduce el peso de estudios con mayor probabilidad de ser publicados (los que encuentran resultados más extremos). Por esto, al usar ésta técnica, estás asumiendo que, de hecho, en el efecto que tratas de encontrar en tu meta-análisis hay un sesgo de publicación, lo que a menudo es una suposición bastante apropiada.

Al usar ésta técnica, tenemos un resultado bastante distinto. Mientras que el meta-análisis original nos daba como resultado un efecto de \~0.15, esta técnica nos estima un efecto de \~0.09. Ha *encogido* nuestro tamaño de efecto, asumiendo que nuestro resultado original estaba sesgado.

Al final, está el *Likelihood ratio test* (en español, "Prueba de la razón de verosimilitud"), que evalúa la bondad del ajuste de dos modelos estadísticos que compiten entre sí, con base en la relación de su verosimilitud[^10]. En este caso, comparando el modelo original, con este modelo con pesos ajustados.

[^10]: Aunque no voy a entrar en detalles respecto a técnicas de inferencia estadística basadas en verosimilitud, si quieres conocer más acerca de estos métodos, así como de estadística Bayesiana (que tiene mucho que ver con verosimilitud) y frecuentista (la que solemos usar, que hace inferencia a partir de valores $p$), con énfasis en las fortalezas y limitaciones de cada enfoque, recomiendo encarecidamente el libro *"Improving Your Statistical Inferences"* de Daniël Lakens [-@lakensImprovingYourStatistical2022]. Este libro, completamente gratuito y abierto, integra además los contenidos de dos cursos gratuitos del mismo autor (*"[Improving Your Statistical Inferences](https://www.coursera.org/learn/statistical-inferences)"* y *"[Improving Your Statistical Questions](https://www.coursera.org/learn/improving-statistical-questions)"*), que también recomiendo hacer a cualquier persona que quiera dedicarse a hacer investigación y use técnicas estadísticas.

Este resultado nos da una tendencia no descartable (`p-val = 0.084043`; menor que 0.10 y por tanto significativa si asumimos un análisis de una cola), que nos da evidencia de que en efecto hay un sesgo de publicación, a pesar de que el *funnel plot* (Figs. \@ref(fig:funnel-plot1), \@ref(fig:funnel-plot1a), \@ref(fig:funnel-plot2) y \@ref(fig:funnel-plot3)) y la regresión de Egger (sección \@ref(reg-egger)), sugerían lo contrario.

## Poder estadístico del meta-análisis

En esta sección explicaré cómo hacer un análisis de poder de un meta-análisis; la idea de ésto es saber si nuestro meta-análisis tiene un poder suficiente para detectar el efecto meta-analizado (en nuestro caso `r round(min(res$beta[1]), 2)` para el meta-análisis original "`res`", o `r round(wf$output_adj$par[2], 2)` el meta-análisis con pesos ajustados "`wf`"). Para este ejemplo, asumiré que el efecto *real* es el encontrado en nuestro análisis original (`r round(min(res$beta[1]), 2)`), pues este efecto es mayor. Si no tuviésemos el poder suficiente para detectar confiablemente ese efecto, menos lo tendríamos para un efecto menor, como el detectado en nuestro meta-análisis con pesos ajustados.

Para hacer esto, usaré el paquete `metameta` [@quintanaGuideMetaPower;@quintanaMetameta2022], que permite calcular y visualizar el poder estadístico de un meta-análisis para detectar un rango de posibles efectos *reales*.

### Instalación de `metameta`

El paquete `metameta` se debe instalar desde GitHub ya que, al día de hoy, no está aún disponible en CRAN[^11].

[^11]: [CRAN](https://cran.r-project.org/) (siglas de *Comprehensive R Archive Network*) es una red de servidores de todo el mundo que almacenan versiones idénticas y actualizadas del código y la documentación de R (incluyendo el lenguaje mismo de R, paquetes aceptados por el equipo de CRAN, y toda la documentación). Es el repositorio oficial y dedicado a R, desde el que normalmente instalas cualquier paquete. [GitHub](https://github.com/), en cambio, es un repositorio general y abierto para para proyectos (típicamente programación) en el que, entre otras cosas, suelen estar alojados todos los paquetes de R en versiones de desarrollador, y antes de ser aceptados en CRAN. Por supuesto, a diferencia de CRAN, GitHub es un repositorio de código general, no específico para R.

Para esto, debemos tener instalado el paquete `devtools`, y usar la función `install_github` que nos permite instalar paquetes directamente desde GitHub.

```{r eval = FALSE}
#se debe tener instalado el paquete devtools
library(devtools)
install_github("dsquintana/metameta")
```

### Análisis de poder

Una vez instalado, podemos cargar el paquete.

```{r}
library(metameta)
```

Como datos, necesitamos no solamente los tamaños de efecto a meta-analizar ($r$ de Pearson transformado a *z* de Fisher), sino además los intervalos de confianza, tal como fueron reportados en varios de nuestros *Forest plots*.

En este caso, voy a asumir un *efecto real* de $r = 0.15$, tal como en nuestro meta-análisis original. Sin embargo, el *efecto real* no es algo que podamos saber (es, de hecho, lo que queremos acercarnos a conocer a través del meta-análisis), así que la función `mapower_ul` del paquete `metameta` calcula el poder de cada meta-análisis para un rango de posibles efectos reales.

```{r}
dat.power <- summary(dat) %>%
  select(yi, ci.lb, ci.ub) %>%
  rename(lower = ci.lb, upper = ci.ub)

power <- mapower_ul(dat = dat.power, observed_es = 0.15, name = "Molloy et al. 2014")

power_list <- list(power$power_median_dat)
power_dat <- power$dat

power_list

power_dat
```

### Visualización del análisis de poder (*Firepower plot*)

Según esto, nuestro meta-análisis sólo tiene un poder estadístico suficiente para detectar de manera confiable efectos mayores a ~0.3, lo que está muy por encima de nuestras estimaciones del efecto real (0.15 en nuestro meta-análisis original, 0.09 en nuestro meta-análisis con pesos ajustados).

```{r}
power.plot <- firepower(power_list)
```

Para ver el *fireplot* que creamos, y ya que lo asigné a un objeto que llamé `power.plot`, debo correr el objeto para ver el resultado (Fig. \@ref(fig:fire-plot1)).

```{r eval = FALSE}
power.plot
```

```{r fire-plot1, fig.height = 2, echo = FALSE, fig.cap = "Fireplot básico de [metameta](https://www.dsquintana.blog/metameta-r-package-meta-analysis/), para un análisis de poder de nuestro meta-análisis. *Observed* hace referencia al tamaño de efecto observado en nuestro meta-análisis original; en este caso, 0.15."}
power.plot$fp_plot
```

Si queremos cambiar los títulos a español, y ya que el objeto `power.plot` contiene dos elementos (`dat` y `fp_plot`, que es propiamente la gráfica). Éste último elemento es de clase `ggplot`, por lo que podemos usar funciones de `ggplot2` para cambiar, por ejemplo, el título del eje $X$ a "Tamaño de efecto", el título de la leyenda a "Poder", y el efecto observado de "*Observed*" a "Observado"[^12] (Fig. \@ref(fig:fire-plot2)). Por ejemplo:

[^12]: Para cambiar el título del eje $X$ usé la función `xlab`; para el título de la leyenda la función `guides` (opción `fill = guide_legend`); y para los valores del eje $X$, la función `scale_x_discrete`}.

```{r fire-plot2, fig.height = 2, message = FALSE, fig.cap = "Fireplot básico de [metameta](https://www.dsquintana.blog/metameta-r-package-meta-analysis/), para un análisis de poder de nuestro meta-análisis, con el texto traducido a español y con la leyenda en una escala discreta para facilitar su lectura. *Observado* hace referencia al tamaño de efecto observado en nuestro meta-análisis original (en este caso, 0.15)."}
power.plot$fp_plot +
  xlab("Tamaño de efecto") +
  guides(fill = guide_legend(title = "Poder", 
                             reverse = TRUE)) +
  scale_x_discrete(labels = c("es_observed" = "Observado",
                              "es01" = 0.1,    
                              "es02" = 0.2,
                              "es03" = 0.3,
                              "es04" = 0.4,    
                              "es05" = 0.5,    
                              "es06" = 0.6,    
                              "es07" = 0.7,
                              "es08" = 0.8,
                              "es09" = 0.9,
                              "es1"  = 1))
```

## Analizar todas las posibles combinaciones de estudios

Ver acá https://www.dsquintana.blog/combinatorial-meta-analysis/

### *Leave-one-out* {#leave-one-out}

La técnica de *leave-one-out* no solo se puede hacer como parte de un diagnóstico de influencia (como se muestra en la sección \@ref(diag-inf)), sino que también se puede hacer para ver la estimación del efecto meta-analizado al excluir cada uno de los estudios de nuestra base de datos.

Hacerlo sólo requiere usar la función `leave1out` del paquete `metafor`, usando como argumento el resultado de nuestro meta-análisis original (en este caso, `res`):

```{r echo = FALSE}
l1o_res <- leave1out(res)
```

```{r eval = FALSE}
leave1out(res)
```

Como puedes ver, nos crea una tabla con las columnas `estimate`, `se`, `zval`, `pval`, `ci.lb`, `ci.ub`, `Q`, `Qp`, `tau2`, `I2` y `H2` (explicadas en la sección \@ref(meta-interp)). Sin embargo, tenemos 16 filas, cada una de las cuales corresponde a los resultados cuando se excluye cada estudio del meta-análisis.

### Meta-análisis combinatorio

Aunque la técnica de *leave-one-out* es útil para determinar la influencia de cada estudio en un meta-análisis (como se explica en las secciones \@ref(diag-inf) y \@ref(leave-one-out)), tiene limitaciones, pues no nos dice nada de cuánto cambia la estimación del efecto meta-analizado cuando excluimos 2 o más estudios. XXXXXXXXX SIGO ACÁ XXXXXXX 

**EXPLICAR LAS VENTAJAS DE HACER TODAS LAS COMBINACIONES POSIBLES**

El número de análisis a realizar puede calcularse usando la fórmula $2^k - 1$, donde $k$ es el número de estudios meta-analizados. Como en nuestro ejemplo estamos meta-analizando 16 estudios, realizarás $2^{16} - 1$ análisis. Es decir, un total de 65535 modelos. Ten en cuenta que ajustar estos 65535 podría bastante tiempo (en mi portátil, que tiene un procesador Intel Core i7-9750H, tardó poco más de 5 minutos, pero puede variar mucho según las características de tu equipo).

Para visualizar esta enorme cantidad de estimaciones de tamaño de efecto, lo mejor es hacer un *visualización gráfica de la heterogeneidad de los estudios* (en inglés, *Graphical Display of Study Heterogeneity* o simplemente *GOSH*), una técnica propuesta por @olkinGOSHGraphicalDisplay2012. 

En R, esto se puede hacer con la función `gosh` del paquete `metafor`, agregando como único argumento el resultado de nuestro meta-análisis original (en nuestro caso, `res`). Voy a asignar el resultado de este análisis a un objeto que llamaré `gp`

```{r cache = TRUE}
gp <- gosh(res)
```

Para graficar los los 65535 modelos, podemos usar la función `plot`, agregando como argumento el resultado de la función `gosh`(`gp` en este caso). En este ejemplo, adicionalmente, usaré el argumento `breaks` para definir el número de puntos de corte (y número de barras) de los histogramas, así como el argumento `labels` para poner los títulos de los ejes en español.

```{r gosh1, message = FALSE, fig.cap = "*GOSH plot* creado con la función  [`gosh`](https://www.metafor-project.org/doku.php/plots:gosh_plot) del paquete [`metafor`](https://www.metafor-project.org/doku.php). Un *GOSH plot* (en inglés, *Graphical Display of Study Heterogeneity* o simplemente *GOSH*) es una visualización gráfica de la heterogeneidad de todos los posibles modelos de meta-análisis ajustados a partir de todas las combinaciones posibles de estudios de nuestra base de datos. Un *GOSH plot* muestra los efectos estimados para cada uno de los modelos en el eje horizontal, y su respectiva heterogeneidad en el eje vertical. Las distribuciones de los efectos (parte superior de la gráfica) y las heterogeneidades (lado derecho de la gráfica) estan representadas como densidades e histogramas."}
plot(gp, 
     breaks = 100,
     labels = c("Coeficiente de correlación transformado en z de Fisher", 
                expression(paste("I"^"2"))))
```

Como puedes ver, los tamaños del efecto suelen estar entre aproximadamente 0.05 y 0.25. Esto es una variación muy grande, que demuestra cómo la elección de los estudios incluidos influye en la estimación del tamaño del efecto que nos dará nuestro meta-análisis.

Para ilustrar mejor esto, podemos a cambiar artificialmente nuestra base de datos, para que contengo valores atípicos. 

Para hacer esto, voy a agregar valores atípicos, cambiando manualmente el tamaño de efecto de 2 de los estudios (en este caso, los estudios 12 y 15, que pasan de tener valores *z* de Fisher de 0.39 y 0.24, a otro mayores, de 0.7 y 0.6, respectivamente). Esta base de datos alterada por supuesto ya no tendía validez para realizar ningún análisis, pues 2 de nuestros resultados son literalmente inventados. Sin embargo, nos permite ver qué sucede cuando una base de datos contiene valores atípicos.

Dado que no quiero afectar nuestra base de datos (`dat`), voy a crear una copia en un objeto llamado `dat_mo`, y después sí cambiar los tamaños de efecto de los estudios 12 y 15 de esa base de datos.

```{r}
dat_mo <- dat
dat_mo$yi[12] = 0.7 
dat_mo$yi[15] = 0.6 
```

Voy a hacer un meta-análisis de esta nueva base de datos alterada (`dat_mo`), y representar los resultados en un *forest plot* (diagrama de bosque).

```{r}
res_mo <- rma.uni(yi, vi, data = dat_mo) 
forest(res_mo)
```

Los valores atípicos introducidos son claramente visibles en el *forest plot* (diagrama de bosque). (estudios 12 y 15).

Now let's run the combinatorial meta-analysis and create a GOSH plot:

```{r cache = TRUE}
gp_mo <- gosh(res_mo)
```

Y el plot 

```{r}
plot(gp_mo, breaks = 100)
```

There is a clear cluster of large effect sizes with high heterogeneity in the top right of the plot. We can specifically highlight the meta-analysis models that included the potential outlier studies:

```{r fig.cap = "Se puede ver en las distribuciones del eje X (distribuciones arriba) cómo los meta análisis que incluyen ese estudio tienden a arrojar estimados más fuertes para la asociación, sesgando el resultado hacia valores más extremos."}
plot(gp_mo, out = 12, breaks = 100,
     labels = c("Coeficiente de correlación transformado en z de Fisher", 
                expression(paste("I"^"2"))))
```

There's a noticeable shift in the distribution of meta-analysis model summary effect size estimates that include study 12.

Ultimately, combinatorial meta-analysis paired with GOSH plots demonstrate how your analysis choices influence your meta-analysis outcomes and conclusions.

# Meta-análisis de correlación con moderador (meta-regresión) {#met-moderation}

\textcolor{red}{Incluir moderadores en nuestro meta-análisis (i.e. hacer una meta-regresión), es una fusión de principios de regresión meta-analíticos y lineales, que sirva para explorar la heterogeneidad. Con esto, podemos saber si existe una asociación lineal entre el resultado de nuestro meta-análisis y una o más covariables.}

\textcolor{red}{La meta-regresión desempeña un papel fundamental en la consideración de los efectos de las covariables, especialmente en presencia de variables categóricas que pueden utilizarse para el análisis de subgrupos.}

## Ejemplo 1: Moderación de una variable continua (edad promedio de los participantes) {#ex.mod1}

Primero, y como ejemplo, vamos a ver si la edad promedio de los participantes de un estudio (en nuestros datos, `meanage`) modera el resultado. Esto es importante, pues hay una enorme variación entre las edades medias de los participantes de los diferentes estudios[^13], lo que podría moderar (afectar) la asociación entre concienciación (*conscientiousness*) y adherencia a la medicación prescrita.

[^13]: De hecho, mientras que en el estudio de `r paste0(dat$authors[which.min(dat$meanage)], " (", dat$year[which.min(dat$meanage)], ")")` la edad promedio fue de `r min(dat$meanage)`, en el estudio de `r paste0(dat$authors[which.max(dat$meanage)], " (", dat$year[which.max(dat$meanage)], ")")` la edad promedio fue de `r max(dat$meanage)`.

Para esto, de nuevo podemos usar la función `rma` de paquete `metafor` y de la misma manera que en la sección \@ref(meta-cor), pero agregando nuestra variable moderadora (`meanage`) al argumento `mods`. En este caso voy a asignar a un objeto llamado `res.modage`, para diferenciarlo del objeto `res` al que asigné el meta-análisis básico, sin moderadores.

```{r}
res.modage <- rma(yi = yi, vi = vi, mods = ~meanage, data = dat)
```

Los resultados, son los siguientes:

```{r}
res.modage
```

Los resultados, que tienen la misma organización que los del análisis sin moderadores (sección \@ref(meta-cor)). Este resultado nos muestra que, a pesar de la gran diferencia de edad entre estudios, la edad no tiene un efecto significativo, como se puede ver en la sección "`Test of Moderators (coefficient 2)`" (al final nos muestra el valor *p* como "\texttt{p-val =  0.2320}"), así como los resultados para el efecto de `meanage` en la tabla `Model Results` (donde nos da el mismo resultado: "\texttt{0.2320}").

### Más información e interpretación de la moderación {#pred-mods}

Para más información, podemos *predecir* el efecto (en este caso, la correlación entre la concienciación y la adherencia a la medicación), a diferentes edades, usando la función `predict`. 

En este ejemplo, como argumentos de esta función incluiré el objeto que contiene el meta-análisis con la edad como variable moderadora (`res.modage`), y los los valores para los cuales quiero saber el coeficiente de correlación predicho (argumento `newmods`); en este ejemplo voy a usar "`seq(20, 80, by = 10)`", lo que produce la secuencia de números de 20 a 80, cada 10 (es decir: **20**, **30**, **40**, **50**, **60**, **70**, **80**), que serán las edades para las cuales obtendré el coeficiente de correlación estimado por el modelo[^14].

[^14]: Escogí edades entre 20 y 80 como referencia, pues están cerca al rango de valores de de las edades promedio de los estudios meta-analizados (`r min(dat$meanage)` a `r max(dat$meanage)`), y con edades cada 10 años, para obtener un número manejable pero informativo de predicciones.

Adicionalmente, voy a convertir esta tabla a un objeto clase `data.frame` (`as.data.frame()`), crearé una nueva variable llamada `meanage` que contiene las edades para las cuales he calculado la predicción (`mutate(meanageage = seq(20, 80, by = 10))`[^15]), y reorganizado el orden de las columnas (`select(7, 1:6)`). Asignaré esta tabla a un objeto llamado `pred.res.modage`.

[^15]: Para agregar los valores de la variable moderadora para los cuales se hace la predicción, alternativamente se puede agregar el argumento `addx = TRUE` a la función `predict` (en este caso, por ejemplo, `predict(res.modage, newmods = seq(20, 80, by = 10), addx = TRUE)`). Sin embargo, para evitar crear columnas adicionales y tener una tabla en un formato más sencillo y claro, he decidido crear la columna `meanage` manualmente. Si usara el argumento `addx = TRUE`, crearía las columnas `X.intrcpt` con el intercepto, y `X.meanage`con los valores de `meanage`.

```{r pred-mod1}
# Calcular efecto ajustado para diferentes edades
pred.res.modage <- predict(res.modage, newmods = seq(20, 80, by = 10)) %>% 
  as.data.frame() %>% 
  mutate_all(~round(., 3)) %>% 
  mutate(meanage = seq(20, 80, by = 10)) %>% 
  select(7, 1:6)
# Ver la tabla
pred.res.modage
```

Con esto, el objeto `pred.res.modage`, al que he asignado esta predicción, tiene las siguientes columnas:

-   **`meanage`**: edad promedio de los participantes de los estudios meta-analizados

-   **`pred`**: valor del efecto predicho (en este caso, coeficiente de correlación transformado en *z* de Fisher), para cada edad promedio

-   **`se`**: error estándar (en inglés *standard error*) del efecto predicho

-   **`ci.lb`**: límite inferior del intervalo de confianza del 95% (en inglés *confidence interval lower bound*)del efecto predicho

-   **`ci.ub`**: límite superior del intervalo de confianza del 95% (en inglés *confidence interval upper bound*) del efecto predicho

-   **`pi.lb`**: límite inferior del intervalo de predicción (en inglés *prediction interval lower bound*), y

-   **`pi.ub`**: límite superior del intervalo de predicción (en inglés *prediction interval upper bound*)

Las columnas `age` (edad) y `pred` (efecto predicho), nos muestran que, para estudios donde los participantes son en promedio más jóvenes, se esperaría una correlación más fuerte; por ejemplo, mientras que para estudios con personas de `r pred.res.modage[1,1]` años de edad en promedio se esperaría una correlación de *z* = `r round(pred.res.modage[1,2], 3)`, para estudios participantes con una edad promedio de `r pred.res.modage[dim(pred.res.modage)[1],1]` años, el modelo estima un efecto de *z* = `r round(pred.res.modage[dim(pred.res.modage)[1],2], 3)`. En otras palabras, en nuestra muestra de estudios, la asociación entre concienciación y adherencia a la medicación tiende a reducirse ligeramente con la edad promedio de la muestra. 

Sin embargo, este efecto moderador de la edad \underline{no es significativo}, por lo que no tenemos evidencia suficiente que nos sugiera que es real, más allá de nuestra muestra de estudios.

#### *Meta-Analytic Scatter Plot* (Gráfico de dispersión meta-analítico)

Alternativamente, cuando tenemos un modelo con moderador, también podemos ver la asociación entre la variable moderadora, y el efecto de cada estudio meta-analizado, a modo de regresión. La función `regplot` hace precisamente esto (Fig. \@ref(fig:reg-plot1)).

```{r reg-plot1, fig.height = 6, fig.cap = "Gráfico de dispersión meta-analítico (*Meta-Analytic Scatter Plot*). El tamaño de los puntos es proporcional al peso que recibieron los estudios en el meta-análisis (puntos más grandes para los estudios con más peso, pues tienen un tamaño de muestra mayor y con un menor error estimado). La línea negra representa el efecto previsto en función del predictor (en este caso \\texttt{meanage}, edad promedio), que por supuesto coincide  con las predicciones del objeto `pred.res.modage` (Output 11, en la sección \\@ref(pred-mods)); la banda gris demilimata por líneas punteadas representa el intervalo de confianza del 95%."}
regplot(res.modage,
        ylab = "Coeficiente de correlación transformado en z de Fisher",
        xlab = "Edad promedio del estudio")
```

### *Forest plot* y *funnel plot* {#plot-mod}

Por supuesto, de estos resultados también puedo crear *forest plots* y *funnel plots*, siguiendo los ejemplos y código de la sección \@ref(meta-cor). Para el *forest plot*, hago a continuación un ejemplo anotado y mejorado[^16] (Fig. \@ref(fig:for-plot-mod1), con un código similar al usado como ejemplo en la Fig. \@ref(fig:for-plot2)). Sin embargo, es importante tener en cuenta que esta opción no creará un resumen del meta-análisis, ya que no tenemos un solo efecto *real* como producto del meta-análisis.

[^16]: La función [`viz_forest`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#creating-forest-plots-with-function-viz_forest) del paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) no puede crear un *forest plot* de un meta-análisis ajustado con `metafor` cuando este modelo contiene variables moderadoras continuas, o cuando tiene como variable moderadora más de una variable categórica. En otras palabras, sólo podrá hacer el *forest plot* si nuestro meta-análisis no tiene moderadores, o tiene un único moderador categórico. Como en este ejemplo nuestro moderador es una variable continua, no es posible usar esta función.

```{r eval = FALSE}
# forest plot con anotaciones adicionales
forest(res.modage,  cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
par(cex = 0.8, font = 2)
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

```{r for-plot-mod1, echo = FALSE, warning = FALSE, fig.height = 3.5, fig.cap = "*Forest plot* básico de [metafor](https://www.metafor-project.org/doku.php), para un meta-análisis incluyendo la edad promedio de los participantes como moderador. En la ilustración gráfica, además de los efectos originales, se puede ver el efecto de cada estudio estimado cuando se incluye el moderador como polígonos (diamantes) de color gris. Sin embargo, ya no obtenemos una fila al final representando el efecto promediado del meta-análisis, ya que no tenemos un solo efecto."}
# forest plot con anotaciones adicionales
par(mar = c(4,0,0,0))
forest(res.modage,  cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
par(cex = 0.8, font = 2)
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

De manera similar, podemos obtener un *funnel plot* de nuestro meta-análisis con moderador. Es importante tener en cuenta que tanto el paquete `weightr` como el paquete `metafor` tienen funciones llamadas `funnel`. Dado que cargamos el paquete `weightr` después, R por defecto intentará intentará crear el *funnel plot* con la función `funnel` del paquete `weightr`, en vez de la función `funnel` del paquete `metafor`. Para evitar este error, tenemos dos opciones: podemos pedirle a R explícitamente que use la función `funnel` del paquete `metafor` con el comando `metafor::funnel`, o podemos pedirle a R que elimine el paquete de la memoria con la función `detach("package:metameta", unload = TRUE)`. En este caso, usaré la primera opción.

Este *funnel plot*, a diferencia los los anteriores, nos mostrará los valores residuales de cada estudio (es decir, qué tanto se alejan del resultado de nuestro meta-análisis, que tiene un valor residual de 0; Fig. \@ref(fig:funnel-plot1)), en vez de los coeficientes de correlación (transformados a $z$ de Fisher).

```{r eval = FALSE}
metafor::funnel(res.modage,
                xlab = "Valor residual",
                ylab = "Error estándar")
```

```{r funnel-plot-mod1, echo = FALSE, fig.height = 5, fig.cap = "*Funnel plot* básico de [metafor](https://www.metafor-project.org/doku.php), para un meta-análisis incluyendo la edad promedio de los participantes como moderador, y con títulos de los ejes en español. La línea punteada vertical representa el efecto meta-analizado que hemos encontrado, así que podemos ver los estudios que encontraron un efecto mayor (derecha de la línea punteada) o menor (izquierda) de éste. **Nota**: Para evitar confunción entre las funciones `funnel` de los paquetes `weightr` y `metafor`, en este caso he usado el comando \\texttt{metafor::funnel} para pedirle a R explícitamente que use la función `funnel` del paquete `metafor`."}
par(mar = c(4,4,0,1))
metafor::funnel(res.modage,
                xlab = "Valor residual",
                ylab = "Error estándar")
```

## Ejemplo 2: Moderación de una variable categórica (controles usados en cada estudio meta-analizado)

Como segundo ejemplo, voy a mirar si el hecho de que los estudios tengan variables que fueron controladas, modera la asociación entre concienciación (*conscientiousness*) y adherencia a la medicación prescrita. Siguiendo los mismos pasos, voy hacer éste análisis, pero voy a asignar este meta-análisis a un objeto llamado `res.contr`. 

```{r}
res.contr <- rma(yi = yi, vi = vi, mods = ~controls, data = dat)
res.contr
```

En éste caso, a diferencia del ejemplo de moderación anteriores, la variable moderadora (`controls`) sí tiene un efecto significativo, como se puede ver en la columna `pval` para el efecto de `controlsnone` (`r scales::pvalue(res.contr$pval[2])`), y en los asteriscos que aparecen al final de esa fila (`***`).

### Más información e interpretación de la moderación {#pred-mods2}

```{r}
pred.res.contr <- predict(res.contr, newmods = c(0, 1)) %>% 
  as.data.frame() %>% 
  mutate_all(~round(., 3)) %>%
  mutate(controls = levels(dat$controls)) %>% 
  rename(yi = pred) %>% 
  select(7, 1:6)
pred.res.contr
```

#### *Meta-Analytic Scatter Plot* (Gráfico de dispersión meta-analítico)

Al igual que en el ejemplo de meta-análisis con moderación de una variable continua (sección \@ref(ex.mod1)), es posible hacer un gráfico de dispersión meta-analítico (*meta-analytic scatter plot*) usando la función `regplot` del paquete `metafor`. Sin embargo, dado que la variable moderadora es categórica, el modelo genera variables *dummy* asignando valores de 0 y 1 a los niveles de esta variable (en este caso, 0 = ningún control; 1 = múltiples controles). Por esto, en el ejemplo a continuación agregué a la descripción del eje $X$ esta información.

```{r reg-plot2, fig.height = 6, fig.cap = "Gráfico de dispersión meta-analítico (*Meta-Analytic Scatter Plot*) básico de [metafor](https://www.metafor-project.org/doku.php) creado con la función \\texttt{regplot}. El tamaño de los puntos es proporcional al peso que recibieron los estudios en el meta-análisis (puntos más grandes para los estudios con más peso, pues tienen un tamaño de muestra mayor y con un menor error estimado). La línea negra representa el efecto previsto en función del predictor (en este caso \\texttt{controls}, controles). La banda gris demilimata por líneas punteadas representa el intervalo de confianza del 95%. Dado que la variable moderadora es categórica, el modelo genera variables *dummy* asignando valores de 0 y 1 a los niveles de esta variable (en este caso, 0 = ningúun control; 1 = múltiples controles), tal y como se describe en el eje *X*. Para una versión más apropiada, ver Fig. \\@ref(fig:reg-plot3)."}
regplot(res.contr,
        ylab = "Coeficiente de correlación transformado en z de Fisher",
        xlab = "Controles (0 = ninguno; 1 = múltiples)")
```

Aunque la figura \@ref(fig:reg-plot2) presenta información correcta, tal vez no es la más adecuada ni la más clara cuando se trata de representar meta-análisis con moderadores categóricos. Por ejemplo, a pesar de que nuestro moderador es un factor (controles) con dos niveles (ninguno, múltiples), en el eje $X$ se representa como una variable continua con valores entre 0 y 1, que además tiene valores intermedios (0.2, 2.4, 0.6, 0.8) que en nuestro caso no tienen sentido.

Sin embargo, de manera un poco más *artesanal*, es posible crear una versión más adecuada usando, por ejemplo, `ggplot2`. El código siguiente permite crear una figura bastante sofisticada usando éste paquete.

```{r eval = FALSE}
# Definir base de datos, así como ejes X (controls) y Y (yi)
ggplot(dat, aes(x = controls, y = yi)) +
  # Agregar puntos para cada estudio, con tamaño y color según tamaño de muestra (ni)
  geom_point(aes(size = ni, color = ni),
             alpha = 0.5) +
  # Definir escala de colores
  scale_colour_gradient(low = "red",
                        high = "blue") +
  # Definir rango de tamaño de los puntos
  scale_size_continuous(range = c(1, 10)) +
  # Combinar leyendas de colores y tamaños de puntos en una sola leyenda
  guides(color = guide_legend(), 
         size = guide_legend()) +
  # Traducir etiquetas del eje X en español
  scale_x_discrete(labels=c("none" = "Ninguno", 
                            "multiple" = "Múltiples")) +
  # Cambiar títulos de ejes a español
  labs(x = "Controles", 
       y = "Coeficiente de correlación \ntransformado en z de Fisher ") +
  # Agregar barras de error para cada categoría, con base en predicción hecha en sección 4.2.1
  geom_errorbar(data = pred.res.contr,
                mapping = aes(ymin = ci.lb, ymax = ci.ub),
                width = 0.1,
                color = "black") +
  # Agregar puntos blancos representando predicción para cada categoría hecha en sección 4.2.1
  geom_point(data = pred.res.contr,
             shape = 21, size = 3,
             color = "black", fill = "white") +
  # Cambiar tptitulo de leyenda
  labs(color = "Tamaño de \nmuestra",
       size = "Tamaño de \nmuestra")
```

El código anterior puede verse algo confuso para quien no haya usado `ggplot2` antes. Por esto, he agregado anotaciones, función por función, para ayudar a su interpretación[^17]. Este código produce la figura \@ref(fig:reg-plot3).

[^17]: Debido a sus enormes y numerosas posibilidades, `ggplot2` es quizás la opción más poderosa para hacer gráficos estadísticos en R; por esto explicar sus bases supera por mucho el alcance de esta guía, y posiblemente requeriría múltiples tutoriales independientes. Sin embargo, hay gran cantidad de opciones disponibles en internet. Por ejemplo, puedes leer este [tutorial](https://rpubs.com/anlope10/562981) [@lopezpenarandaTutorialGgplot22019] o ver este [video](https://youtu.be/BUzTAr_QqKs) [@datademiaAprendeGgplot22018]. 

```{r reg-plot3, echo = FALSE, fig.cap = "Gráfico de dispersión meta-analítico (*Meta-Analytic Scatter Plot*) creado manualmente con [ggplot2](https://ggplot2.tidyverse.org/) para hacer una mejor representación de un moderador categírico. Los puntos de colores representan el coeficiente de correlación en función de la presencia o ausencia de controles. El tamaño de los puntos es proporcional al tamaño de muestra de los estudios inluidos en el meta-análisis (puntos más grandes y azules para los estudios con mayor tamaño de muestra). Los puntos blancos superpuetos representan el efecto estimado para cada categoría, y las barras de error representan los intervalos de confianza del 95%."}
ggplot(dat, aes(x = controls, y = yi)) +
  geom_point(aes(size = ni, color = ni),
             alpha = 0.5) +
  scale_colour_gradient(low = "red",
                        high = "blue") +
  scale_size_continuous(range = c(1, 10)) +
  guides(color = guide_legend(), 
         size = guide_legend()) +
  scale_x_discrete(labels=c("none" = "Ninguno", 
                            "multiple" = "Múltiples")) +
  labs(x = "Controles", 
       y = "Coeficiente de correlación \ntransformado en z de Fisher ") +
  geom_errorbar(data = pred.res.contr,
                mapping = aes(ymin = ci.lb, ymax = ci.ub),
                width = 0.1,
                color = "black") +
  geom_point(data = pred.res.contr,
             shape = 21, size = 3,
             color = "black", fill = "white") +
  labs(color = "Tamaño de \nmuestra",
       size = "Tamaño de \nmuestra") +
  theme_minimal()
```

### *Forest plot* y *funnel plot* {#plot-mod2}

Por supuesto, *forest plots* y *funnel plots* pueden ser creados, tal y como describí en la sección \@ref(plot-mod).

# Conclusiones y recomendaciones generales

Hacer un meta-análisis de correlación en R no es complejo. Sin embargo, la confiabilidad del resultado que te proporcione, dependerá de varios aspectos. 

Primero, debes tener hacer una selección de artículos buena y no sesgada. Esto típicamente incluye:

1) Formular la pregunta de investigación clara, con base en teoría

2) Identificar la bibliografía pertinente

3) Extraer y consolidar los datos de los estudios (en el caso de correlaciones, cuando menos *r* y *n*)

Con esto deberías ya poder hacer una base de datos para un meta-análisis de correlación simple. Mientras tengas en tu base de datos algún identificador de cada estudio, el tamaño de efecto (*r*) y el tamaño de muestra (*n*), tendrías todo lo necesario para hacerlo. Por ejemplo:

| estudio       | ri   | ni  |
|---------------|------|-----|
| Autores (año) | 0.25 | 425 |
| Autores (año) | 0.65 | 45  |
| Autores (año) | 0.12 | 235 |

Adicionalmente, podrías tomar o extraer información de posibles variables moderadoras; por ejemplo, si los estudios se pudieran agrupar según metodología usada o población estudiada, y sospechas que estas variables afectan la correlación encontrada en cada estudio, podrías agregar esta información en una o más variables.

Una vez tengas tu base de datos lista, deberías, cuando menos:

1. Hacer el meta-análisis

  * Reportar información sobre heterogeneidad
  
  * Incluir un diagnóstico de influencia
  
  * Reportar los resultados usando un *forest plot* (diagrama de bosque)
  
  * Mostrar la distribución de los resultados en un *funnel plot* (diagrama de embudo) y estimar el sesgo de estudios pequeños 
  
2. Estimar si hay evidencia de sesgo de publicación

  * Puedes usar el método *trim and fill* (recorte y relleno) o, lo que es mejor, hacer una estimación del modelo de función de peso

Adicionalmente, podrías:

3. Estimar el poder estadístico del meta-análisis y los estudios meta-analizados

4. Hacer un meta-análisis combinatorio)



\newpage

# Referencias

<div id="refs"></div>

# APÉNDICES {.unnumbered}

# (APPENDIX) Appendix {-}  

# Alternativas a `metafor`

Acá he usado principalmente una ruta para hacer meta-análisis basada en el paquete `metafor`, acompañado de `metaviz` para visualizaciones, `weightr` para ajustar pesos y detectar sesgos de publicación, y `metameta` para estimar el poder estadístico de un meta-análisis.

Sin embargo, existen rutas alternativas para realizar meta-análisis en R. El libro *Doing meta-analysis with R: a hands-on guide* [@harrer2021doing] se acompaña del paquete [`dmetar`](https://dmetar.protectlab.org/index.html) [@Harrer2019dmetar], que contiene opciones para hacer meta-análisis tanto a partir de `metafor`, como a partir de `meta` [@BalduzziMeta2019; @schwarzerMetaAnalysis2015].

De manera importante, los objetos generados por `meta` al realizar un meta-análisis permiten hacer otros análisis como *risk of bias* (riesgo de sesgo), inferencia multi-modelo, detección de *outliers* (valores atípicos), y *p-curve* o curva de valores $p$ [@simonsohnPCurveEffectSize2014], así como opciones para hacer gráficos distintos. Para una guía resumida y concreta (en inglés) de estas opciones, recomiendo ver el sitio web del paquete [`dmetar`](http://dmetar.protectlab.org/), y en especial la página [*Get Started*](https://dmetar.protectlab.org/articles/dmetar.html).

# Citas y referencias de paquetes de R

Por supuesto, los paquetes de R que usemos deben ser citados. Una manera fácil de encontrar la cita que los autores de un paquete quieren que usemos, es la función `citation` en R. Simplemente debemos usar esta función, agregando como argumento el nombre del paquete que queremos citar entre comillas. Esto nos dará la referencia en un formato estándar, así como como en un formato `BibTex` que puede ser usado en documentos \LaTeX, o por muchos gestores de referencia (alternativamente nos permite saber los campos como autores, título y demás, si vamos a crear las citas y referencias manualmente).

Por ejemplo, en ésta guía usé `dplyr` [@WickhamDplyr2021] para manipular los datos, y usando la función `citation`, obtengo esta información:

```{r}
citation("dplyr")
```

# Paquetes de R y versiones usados para crear este documento (para garantizar reproducibilidad)

```{r echo = FALSE}
library(pander)
pander(sessionInfo(), locale = FALSE)
```
