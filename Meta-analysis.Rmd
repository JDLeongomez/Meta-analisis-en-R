---
title: 'Meta-análisis de correlaciones y meta-regresión en R:'
subtitle: 'Guía práctica'
author:
  - name: Juan David Leongómez \orcidlink{0000-0002-0092-6298}
    correspondence: false
date: "`r Sys.setlocale('LC_TIME');format(Sys.Date(),'%d %B, %Y')`"
output:
  bookdown::pdf_document2:
    number_sections: yes
    keep_tex:  true
    toc: no
    pandoc_args:
      - '--lua-filter=lua/scholarly-metadata.lua'
      - '--lua-filter=lua/author-info-blocks.lua'
      - '--highlight-style=theme/my_style.theme'
classoption: 
      - bookmarksnumbered
editor_options:
  chunk_output_type: console
geometry: margin=2cm
header-includes: 
  \usepackage{setspace}
  \usepackage{float} 
  \floatplacement{figure}{H}
  \usepackage[utf8]{inputenc}
  \usepackage{fancyhdr}
  \pagestyle{fancy}
  \lhead{Juan David Leongómez}
  \rhead{\textit{Meta-análisis de correlaciones en {R:} Guía práctica}}
  \rfoot{\footnotesize{{doi:}
    \href{https://doi.org/10.5281/zenodo.5640182}{10.5281/zenodo.5640182}}}
  \lfoot{\footnotesize{Versión 2}}
  \renewcommand{\abstractname}{Descripción}
  \usepackage[spanish]{babel}
  \usepackage{hanging}
  \usepackage{amsthm,amssymb,amsfonts}
  \usepackage{tikz,lipsum,lmodern}
  \usepackage[most]{tcolorbox}
  \usepackage{fontawesome5}
  \usepackage{svg}
  \usepackage{multirow,booktabs,caption}
  \renewcommand\spanishtablename{Tabla}
  \DeclareCaptionLabelSeparator*{spaced}{\\[1ex]}
  \DeclareCaptionLabelSeparator{point}{. }
  \captionsetup[table]{labelfont=bf,
    textfont=it,
    format=plain,
    justification=justified,
    singlelinecheck=false,
    labelsep=spaced,
    skip=5pt}
  \captionsetup[figure]{labelfont=bf,
    format=plain,
    justification=justified,
  singlelinecheck=false,labelsep=point,skip=5pt}
  \usepackage{orcidlink}
  \definecolor{iacol}{RGB}{246, 130, 18}
  \definecolor{iacoldark}{RGB}{246, 100, 18}
always_allow_html: yes
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
urlcolor: blue
linkcolor: iacoldark
link-citations: true
bibliography: bib/references.bib
---

```{=latex}
\newtcolorbox[auto counter]{ROut}[2][]{
                lower separated=false,
                colback=white,
                colframe=iacol,
                fonttitle=\bfseries,
                colbacktitle=iacol,
                coltitle=black,
                boxrule=1pt,
                sharp corners,
                breakable,
                enhanced,
                attach boxed title to top left={yshift=-0.1in,xshift=0.15in},
                boxed title style={boxrule=0pt,colframe=white,},
              title=#2,#1}
```
```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(comment = NA)
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options){
  out <- def_hook(x, options)
  return(paste("\\begin{ROut}{Consola de R: Output~\\thetcbcounter}
                \\begin{footnotesize}
                \\begin{verbatim}", 
               x,
               "\\end{verbatim}
                \\end{footnotesize}
                \\end{ROut}"))
})
library(robumeta)
library(metafor)
library(tidyverse)
library(ggpubr)
library(kableExtra)
```

```{=latex}
\begin{center}
Laboratorio de Análisis del Comportamiento Humano (LACH), Facultad de Psicología, Universidad El Bosque, Bogotá, Colombia. Email: \href{mailto:jleongomez@unbosque.edu.co}{jleongomez@unbosque.edu.co}. Web: \href{https://jdleongomez.info/es}{jdleongomez.info}.

\vfill
\textbf{Descripción}
\end{center}

\par
\begingroup
\leftskip3em
\rightskip\leftskip
```
Esta guía contiene todo el código y explicaciones, paso a paso, para hacer un meta-análisis de coeficientes de correlación en R, usando principalmente los paquetes [`metafor`](https://www.metafor-project.org/doku.php) [@viechtbauer2010] y [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) [@KossmeierMetaviz]. Incluye explicaciones básicas para la transformación de coeficientes *r* de Pearson a *z* de Fisher (y viceversa) e interpretación de los resultados, así como creación de *forest plots* y *funnel plots* para meta-análisis de correlaciones simples o con moderadores. Adicionalmente, incluye estrategias para detectar posibles sesgos de publicación usando el paquete [`weightr`](https://www.r-pkg.org/pkg/weightr) [@coburnWeightr2019], así como para determinar el poder estadístico de un meta-análisis usando [`metameta`](https://www.dsquintana.blog/metameta-r-package-meta-analysis/) [@quintanaMetameta2022]. 

**Nota:** Está guía está parcialmente basada en [este video](https://youtu.be/lH4VZMTEZSc), creado por Daniel S. Quintana [-@quintanaHowPerformMetaanalysis2021], pero contiene pasos adicionales o alternativos, así como citas a fuentes primarias, e información complementaria y más detallada. Como tal, asume un manejo básico de R, así como una comprensión de correlaciones y regresiones, y un entendimiento general de los principios del meta-análisis. Sin embargo, de ser necesario y como preámbulo, recomiendo ver [este video introductorio](https://youtu.be/ntBbkOn9D_o) al meta-análisis en *jamovi* [@leongomezMetaanalysis2021] que publiqué anteriormente en mi canal de YouTube [*Investigación Abierta*](https://www.youtube.com/c/InvestigaciónAbierta).

[![Investigación Abierta](images%5CLogo-IA-Rectangulo.pdf)](https://www.youtube.com/c/InvestigaciónAbierta)

```{=latex}
\par
\endgroup
\vfill

\textbf{Cita esta guía como } \hrulefill 

\begin{hangparas}{.25in}{1}
Leongómez, J. D. (2022). Meta-análisis de correlaciones en R: Guía práctica. \textit{Zenodo}. \url{https://doi.org/10.5281/zenodo.5640182}
\end{hangparas}
\newpage

{\hypersetup{hidelinks}
 \setcounter{tocdepth}{5}
 \tableofcontents
}
\newpage
```

# Base de datos de ejemplo

Para los ejemplos usados en ésta guía, usaré la base de datos `dat.molloy2014`, tomada de Molloy et al. [-@molloy2013].

Esta base de datos viene incluida con el paquete `metafor` de R. Básicamente, Molloy et al. [-@molloy2013] estudiaron si existe una asociación entre la concienciación (*conscientiousness*^[Para una definición detallada, ver @johnBigFiveTrait1999]) y la adherencia a la medicación. En otras palabras, ¿las personas más *concienciadas* tienden a cumplir más con la medicación prescrita?

Primero, debemos cargar los principales paquetes que usaré a lo largo de esta guía: `metafor` [@viechtbauer2010] y `metaviz` [@KossmeierMetaviz] para hacer e ilustrar los resultados del meta-análisis, así como `dplyr` [@WickhamDplyr2021] para manipular y organizar la base de datos.

```{r eval = FALSE}
library(metafor)
library(metaviz)
library(dplyr)
```

Como ya hemos cargado el paquete `metafor`, ya podemos cargar la base de datos `dat.molloy2014`. En éste caso, para poder *llamarla* cuando sea necesario, la asignaré a un objeto llamado `dat`.

```{r}
dat <- get(data(dat.molloy2014))
```

Tras asignar la base de datos a este objeto (`dat`), la base de datos se puede ver en la consola de R sencillamente usando como comando el nombre que le dimos al objeto al que lo asignamos (en este caso, `dat`).

```{r}
dat
```

Por supuesto, la salida de la consola no es la más clara, pero para una versión más legible, se puede usar la función `View`, y el nombre de la base de datos o tabla como argumento (en este caso `View(dat)`). Sin embargo, de aquí en adelante mostraré algunas tablas en un formato de impresión, más limpio y fácil de leer.

Voy a volver a cargar la base de datos (sobrescribiendo el objeto `dat`), para organizarla un poco mejor. Primero, agregaré una nueva columna llamada `study_id`, en la que numeraré los estudios del 1 al 16, lo que será útil para identificar cada estudio en algunas gráficas y análisis. A continuación, reorganizaré las columnas para que `study_id` sea la primera, en vez de la última columna. Finalmente, las columnas de variables que son factores (`controls`, `design`, `a_measure`, `c_measure` y `quality`), pueden ser definidas como tal, para evitar pasos adicionales más adelante. En este caso, .

```{r molloy2014}
dat <- get(data(dat.molloy2014)) %>%
  mutate(study_id = 1:16)  %>% #crear columna study_id y agregar número del 1 al 16
  select(study_id, authors:quality) %>% #mover study_id como primera columna
  mutate_at(c("controls", # Transformar variables en factores
              "design",
              "a_measure",
              "c_measure",
              "quality"), 
            as.factor) %>% 
  mutate(controls = fct_relevel(controls, "none", "multiple"))
```

Con esto, la base de datos tiene ahora la siguiente estructura (Tabla \@ref(tab:estructuramod)):

```{r estructuramod, echo = FALSE, message = FALSE}
kable(dat, 
      linesep = "",
      booktabs = TRUE,
      caption = "Estructura de la base de datos con estudios numerados") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down")) %>% 
  footnote(general = "Datos tomados de Molloy et al. (2013).",
           general_title = "Nota:",
           footnote_as_chunk = TRUE)
```

Por supuesto, la columna `authors` tiene los autores de cada estudio a meta-analizar, y la columna `year` el año de publicación. La columna `ni` contiene el tamaño de muestra de cada estudio, y la columna `ri` el coeficiente de correlación de Pearson.

Adicionalmente, en este ejemplo tenemos una serie de posibles moderadores:

-   `controls`: cantidad de variables controladas (ninguna o múltiples)

-   `design`: si se utilizó un diseño transversal o prospectivo

-   `a_measure`: tipo de medida de adherencia (autoinforme u otro tipo de medida más "objetivo")

-   `c_measure`: tipo de medida de concienciación (si se midió con alguna versión del inventario de personalidad NEO o con alguna otra escala)

-   `meanage`: edad promedio de la muestra

-   `quality`: calidad metodológica (la calidad metodológica fue calificada por los autores en una escala de 1 a 4, donde las puntuaciones más altas indican una mayor calidad; para información respecto a cómo se obtuvo esta puntuación, ver el artículo original de Molloy et al. [-@molloy2013]

# Preparación de los datos: transformación de coeficientes *r* de Pearson a *z* de Fisher

Los coeficientes de Pearson no se distribuyen normalmente, lo que podría llevar a calcular varianzas incorrectas, especialmente cuando se trata de correlaciones con tamaños de muestra pequeños. Por esto, lo mejor es transformar los coeficientes *r* de Pearson a *z* de Fisher [@fisherFrequencyDistributionValues1915], que no tienen este problema[^1].

[^1]: Para decirlo de manera más precisa, el problema es que la distribución del coeficiente de correlación de Pearson (*r*), es muy sesgada cuando se trata de variables altamente correlacionadas (positiva, o negativamente). Esto dificulta la estimación de los intervalos de confianza y por tanto la aplicación de las pruebas de significación para coeficientes *r*. La transformación de Fisher de valores *r* a *z* ---que es la [tangente hiperbólica inversa](https://es.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica) de *r*--- resuelve este problema, pues los coeficientes *z* tienen una distribución aproximadamente normal, y una varianza estable a lo largo de diferentes valores posibles de *r* [para una demostración en español, ver @sanchez-brunoTransformacionFisherPara2005].

Para transformar los coeficientes *r* de Pearson a coeficientes *z* de Fisher, usaré la función `escalc` del paquete `metafor`. Los argumentos que requiere esta función, además del tipo de transformación a realizar (en este caso `measure = "ZCOR"`), son los coeficientes de correlación (`ri`), el tamaño de muestra de cada correlación (`ni`), y la base de datos que contiene estos valores (`data`). En nuestro caso, las columnas donde están estos valores, tienen los mismos nombres (`ri`, `ni`). En este ejemplo, asignaré el resultado de esta función al mismo objeto `dat`, que contiene la base de datos, para sobrescribirlo y no crear objetos adicionales.

```{r}
dat <- escalc(measure = "ZCOR", ri = ri, ni = ni, data = dat)
```

Esta función agrega dos nuevas variables: `yi`, que es el tamaño de efecto (en valores *z* de Fisher), y `vi` que es la varianza (Tabla \@ref(tab:estructuramod2)).

```{r estructuramod2, echo = FALSE, message = FALSE}
kable(dat, 
      linesep = "",
      booktabs = TRUE,
      caption = "Estructura de la base de datos, con transformación de los r de Pearon a z de Fisher") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down")) %>% 
  footnote(general = "Las nuevas columnas creadas usando la función \\\\texttt{escalc} 
           (\\\\texttt{yi} como tamaño de efecto y \\\\texttt{vi} como varianza) están 
           resaltadas en naranja",
           general_title = "Nota:",
           footnote_as_chunk = TRUE,
           escape = FALSE) %>% 
  column_spec(12:13, background = "#f68212")
```

# Hacer el meta-análisis {#meta-cor}

Para hacer el meta-análisis, usaré la función `rma` del paquete `metafor`. Esta función requiere especificar los tamaños de efecto (`yi`) y varianzas (`vi`) de los estudios a meta-analizar. En nuestro caso, las columnas donde están estos valores, tienen los mismos nombres (`yi`, `vi`). Asignaré los resultados del meta-análisis a un nuevo objeto llamado `res`.

```{r}
res <- rma(yi = yi, vi = vi, data = dat)
```

Los resultados, son los siguientes:

```{r}
res
```

## Interpretación de los resultados del meta-análisis {#meta-interp}

Vamos a analizar estos resultados de la consola de R por partes:

Primero, nos confirman que ajustamos un modelo con efectos aleatorios (`Random-Effects Model`), a partir de 16 estudios (`k = 16`), y que para estimar $\tau^2$ (tau cuadrado) usamos el método de **máxima verosimilitud restringida**[^2] (`tau^2 estimator: REML`), que se designa como *REML* por sus siglas en inglés .

[^2]: Hay varios métodos disponibles como estimador, además de **máxima verosimilitud restringida** (REML). Sin embargo, si tienes dudas, REML es una buena opción. Cada método tiene ventajas y desventajas que, si tienes interés en mirar, están descritas en la [documentación](https://www.rdocumentation.org/packages/metafor/versions/2.4-0/topics/rma.uni) de la función `rma`.

Posteriormente, nos provee los valores de una serie de estimadores de heterogeneidad:

-   $\tau^2$: `tau^2 (estimated amount of total heterogeneity): 0.0081 (SE = 0.0055)`

-   $\tau$: `tau (square root of estimated tau^2 value): 0.0901`

-   $I^2$: `I^2 (total heterogeneity / total variability): 61.73%`, y

-   $H^2$: `H^2 (total variability / sampling variability):  2.61`

La tercera parte, reporta otra prueba de heterogeneidad, usando el estadístico $Q$:

-   `Test for Heterogeneity:`

    `Q(df = 15) = 38.1595, p-val = 0.0009`

De todos estos, los más comúnmente reportados son $\tau^2$, $\tau$, $I^2$ y $Q$. Cada una de estas medidas tiene ventajas y desventajas, por lo cual tiene sentido reportarlas todas.

-   $I^2$: tiene la ventaja de ser sencillo de interpretar, pues hay criterios generales para heterogeneidad baja, moderada y alta (típicamente 25%, 50%, and 75%, respectivamente). Sin embargo, es muy sensible a los tamaños de muestra de los estudios meta-analizados (por ejemplo, si en tu meta-análisis hay estudios con tamaños de muestra muy grandes, esto va a sesgar tu $I^2$).

-   $Q$: aunque no es sensible al tamaño de muestra, es sensible al número de estudios meta-analizados. Tiene la ventaja de ser un test de hipótesis, y como tal, puede ser interpretado a partir de su valor *p*.

-   $\tau^2$: no tiene problemas de sensibilidad a los tamaños de muestra o número de estudios meta-analizados, pero es más difícil de interpretar. $\tau^2$ es una estimación de la varianza de los tamaños de los efectos reales entre los estudios meta-analizados. Se usa, principalmente, para asignar pesos a cada estudio [para más información, ver @borensteinIdentifyingQuantifyingHeterogeneity2009].

En nuestro caso, el estadístico $Q$ sugiere que hay una heterogeneidad significativa en los estudios meta-analizados ($p$ = 0.0009). $I^2$, sugiere una heterogeneidad moderada, lo que quiere decir que se estima que más de la mitad (61.73%) de la varianza se deriva de diferencias en los tamaños de efecto.

Más abajo, el *output* de la consola de R nos muestra los resultados de nuestro meta-análisis (`Model results`); en otras palabras, ¿cuál es el tamaño de efecto de la asociación entre concienciación (*conscientiousness*) y la adherencia a la medicación, según nuestro meta-análisis?

Esta parte nos provee varios resultados:

-   `Estimate (0.1499)`: estimado de la correlación entre concienciación y adherencia a la medicación, en este caso en valores *z* de Fisher, pues así transformamos los coeficientes de cada estudio

-   `se (0.0316)`: error estándar del estimado de la asociación (en valores *z* de Fisher)

-   `zval (4.7501)`: estadístico *Z* (mayúscula) que comprueba la media de una distribución. No se debe confundir con la transformación de coeficientes de correlación a *z* de Fisher (minúscula); este estadístico no nos provee una estimación de la asociación entre las variables correlacionadas, sino, de manera similar a una prueba *t*, nos sugiere si nuestra media (para el caso, el resultado de nuestro meta-análisis), se diferencia de 0 (o una correlación nula). Cuando *Z* es mayor a 1.96 (o menor a -1.96), nuestro resultado está en el 5% extremo de la distribución *Z* y sería significativo con un $\alpha$ tradicional de 0.05 (dos colas)

-   `pval (<.0001)`: valor *p* de la correlación meta-analizada

-   `ci.lb (0.0881)`: límite inferior del intervalo de confianza (*confidence interval lower bound*) de la correlación meta-analizada (en valores *z* de Fisher)

-   `ci.ub (0.2118)`: límite superior del intervalo de confianza (*confidence interval upper bound*) de la correlación meta-analizada (en valores *z* de Fisher)

-   Nivel de significación (`***`): representación con asteriscos (o un punto) del nivel de significación

-   `Signif. codes: 0 ’***’ 0.001 ’**’ 0.01 ’*’ 0.05 ’.’ 0.1 ’ ’ 1`: Clave para interpretar los niveles de significación. Aunque puede parecer complejo, básicamente, quiere decir que tres asteriscos (`***`) representan un valor *p* entre 0 y 0.001 (lo que comúnmente se representa como *p* \< .001); dos asteriscos (`**`) un valor *p* entre 0.001 y 0.01 (*p* \< .01); un asterisco (`*`) un valor *p* entre 0.01 y 0.05 (*p* \< .05); un punto (`.`) un valor *p* entre 0.05 y 0.01 (*p* \< .1, que ya no es significativo); y si no hay ningún símbolo, un valor *p* entre 0.1 y 1 (*p* > .1, no significativo)

En este caso, el meta-análisis nos sugiere que en efecto existe una asociación positiva entre concienciación y adherencia a la medicación (coeficiente de correlación transformado en *z* de Fisher = .1499), con un error estándar de 0.0316. Así mismo, sugiere que esa asociación es significativa (*Z* = 4.7501, $p$ < .0001), y nos muestra el intervalo de confianza al 95% (o IC 95%); los intervalos de confianza (en este caso al 95%) lo que estiman es que, si hiciéramos 100 muestras independientes, 95 de éstas contendrían una asociación que estaría entre los límites inferior (*z* = .0881) y superior (*z* = .2118) de estos intervalos de confianza.

Esto se podría resumir, por ejemplo, como:

> El resultado meta-analizado sugiere que existe una asociación positiva entre concienciación y adherencia a la medicación (*z* ± *se* = 0.15 ± 0.032, IC 95% [0.09, 0.21]; *Z* = 4.75, $p$ < .0001). Sin embargo, es importante considerar que hay heterogeneidad entre los estudios meta-analizados ($\tau^2$ ± *se* =  0.0081 ± 0.0055; $\tau$ = 0.0901; $Q$(15) =  38.16, $p$ < .001; $I^2$ = 61.7%).

### Alternativa: Reportar el estimado como *r* de Pearson en vez de *z* de Fisher

Para reportar la correlación, si prefieres reportar coeficientes *r* de Pearson en vez de la transformación a *z* de Fisher, puedes transformar los valores *z* de Fisher de vuelta a *r* de Pearson. Para esto existen múltiples opciones en R, incluyendo simplemente usar la función `tanh`, que calcula la tangente hiperbólica, o la función `fisherz2r` del paquete `psych` [@revellePsych2021]. Por ejemplo, para transformar el estimado de nuestro meta-análisis a *r* de Pearson, solo debo usar alguna de esas funciones, y agregar el valor *z* (0.1499 en nuestro caso) como único argumento:

```{r message = FALSE}
tanh(0.1499)
library(psych)
fisherz2r(0.1499)
```

Cualquiera de estas opciones nos da un valor de *r* = 0.1487872, muy similar al obtenido (*z* = 0.1499). Esto se debe a que, para coeficientes *r* de Pearson entre -0.4 y 0.4, la transformación a valores *z* de Fisher produce resultados muy similares (Fig. \@ref(fig:rvsz)). 

```{r rvsz, echo = FALSE, message = FALSE, warning = FALSE, fig.height = 4, fig.cap = "Asociación entre coeficientes de correlación *r* de Pearson (eje *X*), y su transformación a *z* de Fisher (eje *Y*). La línea naranja representa la asociación entre valores *r* y *z*; como referencia, la línea negra punteada representa igualdad entre ejes (*y* = *x*). Como se puede ver, cuando *r* está aproximadamente entre -0.4 y 0.4 (rectángulo gris), los valores *r* y *z* son casi idénticos. Para valores más extremos, el valor de *z* se aleja progresivamente del valor de *r* (hasta el infinito)."}

library(tidyquant)

rVsz <- tibble(r = c(seq(-0.999, -0.901, by = 0.001), 
                     seq(-0.9, 0.9, by = 0.01), 
                     seq(0.901, 0.999, by = 0.001))) %>%
  mutate(z = atanh(r))
  
ggplot(rVsz, aes(x = r, y = z)) +
  annotate("rect", xmin = -0.4, xmax = 0.4, ymin = -Inf, ymax = Inf, alpha = 0.2) +
  annotate("text", x = 0, y = 0.2, 
                label = expression(paste("Mínima diferencia entre ", italic(r)," y ", italic(z))), 
           parse = TRUE,
           angle = 16,
           size = 2) +
  geom_smooth(se = FALSE, color = "#F68212") +
  geom_segment(aes(x = -1, xend = 1, y = -1, yend = 1), lty = "dotted", alpha = 0.1) +
  xlim(-1, 1) +
  scale_x_continuous(breaks = round(seq(-1, 1, by = 0.1),1)) +
  scale_y_continuous(breaks = round(seq(-3, 3, by = 0.2),1)) +
  labs(x =  expression(paste("Coeficiente de correlación (", italic("r"), ") de Pearson")),
       y = expression(paste("Transformación a ", italic(" z"), " de Fisher"))) +
  theme_tq()
```

Por supuesto, si decides reportar los resultados de tu meta-análisis en coeficientes *r* de Pearson, siempre puedes hacer lo mismo con el error estándar y los límites del intervalo de confianza al 95% (todos valores en *z* de Fisher, pues fue el tamaño de efecto que meta-analizamos).

## Más información sobre heterogeneidad

Es importante tener en cuenta que la heterogeneidad no es un *supuesto* que se deba cumplir al hacer un meta-análisis, y por ende una heterogeneidad moderada o alta no invalida sus resultados. Sencillamente es información útil que se debe reportar y tener en cuenta al interpretar el resultado de un meta-análisis. En este caso, la presencia de heterogeneidad sugiere que los estudios meta-analizados varían y no suelen reportar resultados similares.

De manera general, y para decirlo de manera más técnica, la presencia de heterogeneidad estadística es indicativa de una variación entre los estudios en la magnitud y la dirección de la estimación del efecto estudiado [para más información y ejemplos, ver @sedgwickMetaanalysesWhatHeterogeneity2015]. 

Por esto, reportar información detallada acerca de la heterogeneidad de los estudios meta-analizados es siempre útil. De hecho, además de reportar los estadísticos $\tau^2$, $\tau$, $I^2$ y $Q$ (como expliqué en la sección \@ref(meta-interp)), podemos fácilmente calcular los intervalos de confianza para $\tau^2$, $\tau$, e $I^2$ (además de $H^2$, que no he usado) con la función `confint`.

```{r}
confint(res)
```

Para $\tau^2$, el hecho de que los límites del intervalo de confianza no crucen el 0 (es decir, no hay un límite negativo y otro positivo; en nuestro caso, ambos son positivos:  IC 95% [0.0017, 0.0378]), también sugiere que que hay heterogeneidad entre los estudios que meta-analizamos.

Estos intervalos de confianza que también pueden ser reportados junto a sus correspondientes  estadísticos. Entonces, esto se podría resumir, por ejemplo, como:

> El resultado meta-analizado sugiere que en efecto existe una asociación positiva entre concienciación y adherencia a la medicación (*z* ± *se* = 0.15 ± 0.032, IC 95% [0.09, 0.21]; *Z* = 4.75, $p$ < .0001). Sin embargo, es importante considerar que hay heterogeneidad entre los estudios meta-analizados ($\tau^2$ ± *se* =  0.0081 ± 0.0055, IC 95% [0.0017, 0.0378]; $\tau$ = 0.0901, IC 95% [0.0412, 0.1944]; $Q$(15) =  38.16, $p$ < .001; $I^2$ = 61.7%, IC 95% [25.2799%, 88.2545%]).

## Diagnóstico de influencia

Otro aspecto importante de un meta-análisis, es determinar si alguno(s) de los estudios meta-analizados es(son) particularmente influyente(s) en nuestro resultado[^3]. Para esto, se suele usar la técnica conocida como *leave-one-out*, que se refiere al resultado del meta-análisis cuando se excluye cada estudio; al estimar cómo y cuánto cambia el resultado del modelo de meta-análisis al excluir cada estudio, podemos estimar su influencia en el resultado. Dicho de otra manera, si al excluir un estudio el resultado cambia mucho, sabemos que ese estudio tiene gran influencia en el meta-análisis y sería mejor excluirlo. 

Para hacer un análisis de influencia, podemos usar la función `influence` del paquete `metafor`, cuyo resultado, en este caso, asignaré a un objeto llamado `inf.res`.

[^3]: Por ejemplo, si estuviésemos meta-analizando 20 estudios, de los cuales 19 tienen un *n* de 100, pero el otro tiene un *n* de 10.000, éste último tendrá una influencia enorme en nuestro resultado. Sería preocupante que nuestro meta-análisis sea dependiente principalmente de un único estudio.

```{r}
inf.res <- influence(res)
```

Dado que lo asigné a un objeto (`inf.res`), para ver el resultado, debo usar como comando el nombre que le di al objeto.

```{r}
inf.res
```

Esto me muestra gran cantidad de información de cada estudio (en este caso, lo presento como una tabla sin formato, tal cual se ve en la consola de R). Las columnas que incluye son:

-   `rstudent`: residuo estandarizados externamente. Esto **no** corresponde al coeficiente de correlación de cada estudio, sino a la diferencia entre el tamaño de efecto observado en cada estudio, y la predicción de dicho valor cuando dicho estudio se elimina del meta-análisis

-   `dffits`: diferencia de ajuste(s) (en inglés *difference in fit(s)*). Es una medida diagnóstica de la influencia de cada punto en una regresión (en este caso, cada estudio en un meta-análisis) propuesta originalmente por Belsley, Kuh y Welsch [-@belsleyRegressionDiagnosticsIdentifying1980]

-   `cook.d`: Distancia de Cook (en inglés, *Cook's distance*). Es otra medida diagnóstica de la influencia, propuesta originalmente por Cook [-@cookDetectionInfluentialObservation1977]. Es conceptualmente idéntica a DFFITS (`dffits`), y he hecho existe una fórmula para convertir una medida en la otra [@Henry2003]. Aunque no hay un acuerdo absoluto respecto, comúnmente se asume que valores mayores a 1 ($D_{i} > 1$), representan puntos altamente influyentes en un modelo [@cookResidualsInfluenceRegression1982], que probablemente deban ser excluidos

-   `cov.r`: relación (o proporción) de covarianza. Es el determinante de la matriz de varianza-covarianza de las estimaciones de los parámetros basadas en el conjunto de datos, cuando cada estudio se elimina del meta-análisis, dividido por el mismo determinante de la matriz de varianza-covarianza cuando se incluyen todos los estudios. Básicamente, un valor menor a 1 indica que la eliminación de ese estudio produce estimaciones más precisas de los coeficientes del modelo

-   `tau2.del`: es la heterogeneidad (residual) $\tau^2$ cuando se elimina cada estudio

-   `QE.del`: similar al resultado anterior, este se refiere al estadístico $Q$ obtenido cuando se excluye cada estudio

-   `hat`: los valores *hat* ($h$) son una medida estandarizada de la distancia de cada punto a la media de la variable predictora. Mientras valores cercanos a 0 indican que no hay un valor preocupante, valores cercanos a 1, aunque no indican directamente alta influencia de algún punto, ciertamente nos indican que vale la pena investigar más. Los valores *hat* están abiertos a la interpretación, pero un valor de corte que es común es el doble de la media de los todos valores *hat* ($\overline{h}$); cualquier estudio con un valor mayor debe ser examinado con cuidado

-   `weight`: peso asignado a cada estudio

-   `dfbs`: el valor de `dfbs` (o *DFBETAS*) indica cuántas desviaciones estándar cambia el coeficiente estimado después de excluir cada estudio del modelo de meta-análisis 

-   `inf`: por suerte, esta columna `inf` resume esta información por nosotros. Cualquier estudio que se considere influyente, teniendo en cuenta la diferencia de ajuste, la distancia de Cook, los valores *hat* o *DFBETAS*, será señalado acá como influyente, usando asteriscos.

Aunque hay mucha información, lo más importante ahora es mirar la última columna, llamada `inf`. Si ahí aparecieran asteriscos para algún estudio meta-analizado (que no es nuestro caso), sugeriría que ese estudio es particularmente influyente y podría ser necesario eliminarlo del meta-análisis.

Por último, podemos también ver ésta información que tenemos guardada en el objeto `inf.res`, de manera gráfica, usando la función `plot` (Fig. \@ref(fig:infplot)).

```{r infplot, fig.height = 7, fig.cap = "Diagnóstico de influencia. Estudios particularmente influyentes serían representados con un punto rojo. Los números 1 a 16 en el eje X representan cada estudio, como lo definimos en columna \\texttt{study\\_id} de la Tabla \\@ref(tab:estructuramod). En este caso, no hay ningún estudio que se considere demasiado influyente, por lo éste análisis sugiere que podemos estar tranquilos con nuestro meta-análisis."}
plot(inf.res)
```

## *Forest plot* (diagrama de bosque)

Para hacer un diagrama de bosque (*forest plot*) con [`metafor`](https://www.metafor-project.org/doku.php) resumiendo nuestro meta-análisis, solo tenemos que usar la función `forest`, usando como argumento el objeto al que asignamos los resultados de nuestro meta-análisis (`res`; esto produce la Fig. \@ref(fig:for-plot1)).

```{r eval = FALSE}
forest(res)
```

```{r for-plot1, echo = FALSE, fig.height = 5.5, fig.cap = "Forest plot básico de [metafor](https://www.metafor-project.org/doku.php). Para cada estudio meta-analizado, tenemos el efecto (correlación, en este caso en valores *z* de Fisher), así como sus intervalos de confianza entre paréntesis cuadrados. Esta misma información está representada gráficamente, con los cuadrados representando el efecto de cada estudio así como sus intervalos de confianza como barras de error, y el tamaño de muestra representado por el tamaño del cuadrado. Bajo estos resultados, tenemos nuestro meta-análisis, con el mismo formato en texto, pero representando el efecto y sus intervalos de confianza con un diamante."}
par(mar = c(4,0,0,0))
forest(res)
```

Como se puede ver en las Figuras \@ref(fig:for-plot1), \@ref(fig:for-plot2) y \@ref(fig:for-plot3b) (que son versiones del mismo *forest plot*), no es una sorpresa que el análisis nos sugiera bastante heterogeneidad; las correlaciones encontradas entre los diferentes estudios varían mucho (están entre `r min(dat$ri)` y `r max(dat$ri)`), y aunque son positivas en la mayoría de los casos (en algunos claramente positivas), en otros casos son prácticamente 0 o incluso negativas.

Para una versión más completa y anotada, también usando el *plot* básico de [`metafor`](https://www.metafor-project.org/doku.php), pero agregando encabezados de cada columna en español, nombres de los estudios meta-analizados[^4] así como una columna con los pesos dados a cada estudio, y detalles del modelo final[^5], podemos hacer algo como esto:

[^4]: En este caso, y dado que tenemos la lista de autores y años de publicación en columnas separadas, pegando las columnas `authors` y `year` separadas por una coma y un espacio: `paste(dat$authors, dat$year, sep = ", ")` como argumento `slab`.

[^5]: Estas opciones están explicadas [acá](https://search.r-project.org/CRAN/refmans/metafor/html/forest.rma.html).

```{r eval = FALSE}
# forest plot con anotaciones adicionales
forest(res, cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L),
       mlab = bquote(paste("Modelo EA: Q(", .(res$k - res$p), ") = ",
     .(formatC(res$QE, digits = 2, format = "f")),
     ", p ", .(scales::pvalue(res$pval)), "; ", I^2, " = ",
     .(formatC(res$I2, digits = 1, format = "f")), "%")))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
op <- par(cex = 0.8, font = 2) 
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

```{r for-plot2, echo = FALSE, fig.height = 5, fig.cap = "*Forest plot* anotado, creado con [metafor](https://www.metafor-project.org/doku.php). En esta versión agregué algunos encabezados en español, así como estadísticos generales del modelo de meta-análisis. Modelo EA se refiere al modelo meta-analizado, de efectos aleatorios."}
# forest plot con anotaciones adicionales
par(mar = c(4,0,0,0))
forest(res, cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L),
       mlab = bquote(paste("Modelo EA: Q(", .(res$k - res$p), ") = ",
     .(formatC(res$QE, digits = 2, format = "f")),
     ", p ", .(scales::pvalue(res$pval)), "; ", I^2, " = ",
     .(formatC(res$I2, digits = 1, format = "f")), "%")))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
op <- par(cex = 0.8, font = 2) 
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

O, para un *forest plot* incluso más sofisticado, se puede usar la función [`viz_forest`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#creating-forest-plots-with-function-viz_forest) del paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html).

```{r eval = FALSE}
# A. Variante "classic" (no tiene que ser definida, pues es la opción por defecto)
viz_forest(res, 
           study_labels = paste(dat$authors, dat$year, sep = ", "),
           xlab = "Correlación", 
           annotate_CI = TRUE,
           summary_label = "Resumen",
           text_size = 2.6,
           x_trans_function = tanh)

# B. Variante "thick"
viz_forest(res, 
           study_labels = paste(dat$authors, dat$year, sep = ", "),
           xlab = "Correlación", 
           variant = "thick",
           col = "Greens",
           annotate_CI = TRUE,
           summary_label = "Resumen",
           text_size = 2.6,
           x_trans_function = tanh)

# C. Variante "rain"
viz_forest(res, 
           study_labels = paste(dat$authors, dat$year, sep = ", "),
           xlab = "Correlación", 
           variant = "rain",
           col = "Oranges",
           annotate_CI = TRUE,
           summary_label = "Resumen",
           text_size = 2.6,
           x_trans_function = tanh)
```

Con el código anterior genero las siguientes tres versiones del mismo *forest plot* (Fig. \@ref(fig:for-plot3b)) usando diferentes variantes y escalas de colores, y transformando de vuelta los coeficientes de *z* de Fisher a *r* de Pearson (con el argumento `x_trans_function = tanh`).

Por supuesto, es cuestión de gusto cuál usar.

```{r for-plot3, echo = FALSE, fig.height = 3}
library(metaviz)
p.classic <- viz_forest(res, 
                        study_labels = paste(dat$authors, dat$year, sep = ", "),
                        xlab = "Correlación", 
                        annotate_CI = TRUE,
                        summary_label = "Resumen",
                        text_size = 2.6,
                        x_trans_function = tanh)

ggarrange(p.classic,
          labels = c("A"))
```

```{r for-plot3b, echo = FALSE, fig.height = 6, warning = FALSE, fig.cap = 'Variantes de *forest plots* creados con  [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html). **A.** Variante clásica (opción por defecto). **B.** Variante "thick" y escala de colores "Greens". **C.** Variante "rain" y escala de colores "Oranges".'}
p.thick <- viz_forest(res, 
                      study_labels = paste(dat$authors, dat$year, sep = ", "),
                      xlab = "Correlación", 
                      variant = "thick",
                      col = "Greens",
                      annotate_CI = TRUE,
                      summary_label = "Resumen",
                      text_size = 2.6,
                      x_trans_function = tanh)

p.rain <- viz_forest(res,
                     study_labels = paste(dat$authors, dat$year, sep = ", "),
                     xlab = "Correlación", 
                     variant = "rain",
                     col = "Oranges",
                     annotate_CI = TRUE,
                     summary_label = "Resumen",
                     text_size = 2.6,
                     x_trans_function = tanh)

ggarrange(p.thick, p.rain,
          labels = c("B", "C"),
          nrow = 2)
```

## *Funnel plot* (diagrama de embudo) y sesgo de estudios pequeños

En este punto, es en donde más errores se cometen. Las pruebas más comunes para evaluar sesgos de publicación, son la evaluación de la asimetría en el *funnel plot* (diagrama de embudo), y la regresión (o test) de Egger [@eggerBiasMetaanalysisDetected1997].

Sin embargo, el principal error que la mayoría de los investigadores (meta-analistas) cometen, es que simplemente basándose en éstos métodos, concluyen que un meta-análisis tiene (o no) riesgo de sufrir de un sesgo de publicación^[Por supuesto, yo mismo soy culpable de haber hecho esto en el pasado, incluyendo algunos comentarios en mi video sobre meta-análisis en *jamovi* [@leongomezMetaanalysis2021].]. Sin embargo, estos métodos, no son pruebas exclusivas de sesgo de publicación, sino de sesgo de estudios de tamaño muestral pequeño [ver e.g. @schwarzerSmallStudyEffectsMetaAnalysis2015], que pueden incluir sesgo de publicación, pero no se centran exclusivamente en éste.

A pesar de esto, tanto la regresión de Egger como el *funnel plot*, son interesantes dado que el sesgo de estudios pequeños es importante.

### *Funnel plot*

Para crear un *funnel plot* con [`metafor`](https://www.metafor-project.org/doku.php), de nuestro meta-análisis, solo tenemos que usar la función `funnel`, usando como argumento el objeto al que asignamos los resultados de nuestro meta-análisis (`res`). Con esto, generamos la Figura \@ref(fig:funnel-plot1).

```{r eval = FALSE}
funnel(res)
```

```{r funnel-plot1, echo = FALSE, fig.height = 5, fig.cap = "*Funnel plot* básico de [metafor](https://www.metafor-project.org/doku.php). Para cada estudio meta-analizado, tenemos el efecto (correlación, en este caso en valores *z* de Fisher) en el eje *X*, así como su error estándar en el eje *Y*. La línea punteada vertical representa el efecto meta-analizado que hemos encontrado, así que podemos ver los estudios que encontraron un efecto mayor (derecha) o menor (izquierda) que éste. A primera vista no parece haber mucha asimetría, pero es importante tener en cuenta que es un análisis muy subjetivo."}
par(mar = c(4,4,0,1))
funnel(res)
```

O, si queremos cambiar los títulos de los ejes, por ejemplo escribiéndolos en español, podemos hacerlo agregando los argumentos `xlab` (para el eje $X$) y/o `ylab` (para el eje $Y$), como se ve en la Figura \@ref(fig:funnel-plot1a).

```{r eval = FALSE}
funnel(res, 
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       ylab = "Error estándar")
```

```{r funnel-plot1a, echo = FALSE, fig.height = 5, fig.cap = "Funnel plot básico de [metafor](https://www.metafor-project.org/doku.php), con títulos de ejes en español. Para cada estudio meta-analizado, tenemos el efecto (correlación, en este caso en valores *z* de Fisher) en el eje *X*, así como su error estándar en el eje *Y*. La línea punteada vertical representa el efecto meta-analizado que hemos encontrado, así que podemos ver los estudios que encontraron un efecto mayor (derecha) o menor (izquierda) que éste."}
par(mar = c(4,4,0,1))
funnel(res, 
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       ylab = "Error estándar")
```

De nuevo, para una versión más sofisticada, se puede usar el paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html), usando la función [`viz_funnel`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#creating-funnel-plots-with-viz_funnel). Hay muchas opciones, pero como ejemplo, usaré la versión por defecto, agregando solo la línea de la regresión de Egger (`egger = TRUE`; ver sección \@ref(reg-egger), más adelante), transformando los tamaños de efecto de regreso a $r$ de Pearson (`x_trans_function = tanh`), y con los títulos de los ejes en español (Fig. \@ref(fig:funnel-plot2)).

```{r funnel-plot2, fig.height = 4.5, warning = FALSE, fig.cap = "*Funnel plot* creado con [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html). En azul, se representa el área donde estudios, según su error (y su tamaño de muestra), tendrían un efecto significativo al 5% (i.e. $p$ > 0.05), y fuera de ésta, donde tendrían un efecto significativo al 1% (i.e. $p$ > 0.01). La línea negra vertical representa el efecto meta-analizado, y el triángulo a partir de su inicio, el área donde se ubican los estudios que no se diferencian significativamente del resultado del meta-análisis. La línea roja punteada, representa la regresión de Egger."}
viz_funnel(res, 
           egger = TRUE,
           x_trans_function = tanh,
           ylab = "Error estándar",
           xlab = "Coeficiente de correlación")
```

Alternativamente, el paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) tiene la función [`viz_sunset`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#sunset-power-enhanced-funnel-plots), que permite además mostrar el poder estadístico (o potencia) de los estudios meta-analizados para detectar un efecto de interés mediante una prueba de Wald de dos colas. De ser necesario, para entender las bases del poder estadístico, recomiendo ver [esta serie de videos](https://youtube.com/playlist?list = PLHk7UNt35ccVdyHqnQ6oXVYA6JBNFrE1x) [@leongomezPoderRvid2020] y/o, para mayor profundidad, leer [esta guía](https://doi.org/10.5281/zenodo.3988776) [@leongomezAnalisisPoderEstadistico2020] que publiqué anteriormente.

A continuación, muestro dos versiones de *funnel plots* creados con la función `viz_sunset` (Fig. \@ref(fig:funnel-plot3)). En ambos casos, agregué el efecto *real* estimado a partir del meta-análisis (`contours = TRUE`), y transformé los tamaños de efecto de regreso a $r$ de Pearson (`x_trans_function = tanh`).

```{r eval = FALSE}
# A. Escala de poder discreta
viz_sunset(res,
           contours = TRUE,
           x_trans_function = tanh)

# B. Escala de poder contínua
viz_sunset(res, 
           contours = TRUE,
           x_trans_function = tanh, 
           power_contours = "continuous")
```

```{r funnel-plot3, message = TRUE, echo = FALSE, fig.height = 8.5, fig.width = 6, warning = FALSE, fig.cap = "Dos versiones de funnel plot creados con [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html), usando la función viz-sunset, que estima el poder de cada estudio para detectar un efecto de interés. **A.** Poder representado por bandas dicretas de color. **B.** Poder representado de manera contínua en una escala de color. En ambos casos, y tal como en la Fig. \\@ref(fig:funnel-plot2), el efecto real está representado como una línea vertical, y el triángulo a partir de su inicio representa el área donde se ubican los estudios que no se diferencian significativamente del resultado del meta-análisis."}
p.suna <- viz_sunset(res, 
                     contours = TRUE,
                     x_trans_function = tanh)
p.sunb <- viz_sunset(res, 
                     contours = TRUE,
                     x_trans_function = tanh,
                     power_contours = "continuous")
  
ggarrange(p.suna, p.sunb,
          labels = "AUTO",
          nrow = 2)
```

### Regresión de Egger {#reg-egger}

Para hacer una prueba formal de sesgo de estudios pequeños [@sternePublicationRelatedBias2000; @schwarzerSmallStudyEffectsMetaAnalysis2015], podemos hacer una prueba o regresión de Egger [@eggerBiasMetaanalysisDetected1997]. En [`metafor`](https://www.metafor-project.org/doku.php), esto se hace con la función `regtest`, de nuevo usando como argumento el objeto al que asignamos el resultado de nuestro meta-análisis (`res`).

```{r eval = FALSE}
regtest(res)
```

Como se puede ver, la prueba de Egger no muestra un resultado significativo (`z = 1.0216, p = 0.3070`).

```{r echo = FALSE}
regtest(res)
```

Con base en esto, y la inspección visual subjetiva del *funnel plot*, muchos investigadores concluyen que no hay sesgo de publicación. Sin embargo, como mencioné antes, estas pruebas no se centran en el sesgo de publicación sino en el sesgo de estudios pequeños. En otras palabras, con base en esto, lo único que podemos concluir correctamente, es que no hay sesgo de estudios pequeños (más adelante, en la sección \@ref(sesgo-pub), explicaré cómo evaluar si hay sesgo de publicación).

## Sesgo de publicación (*publication bias*) {#sesgo-pub}

Existen diferentes opciones para estimar el sesgo de publicación de un meta-análisis. En esta sección, me centraré en dos: el método de recorte y relleno (*trim and fill*), y la estimación del modelo de función de peso.

### Método *trim and fill* (recorte y relleno) {#trim-fill}

El método de recorte y relleno (*trim and fill*) es una técnica no paramétrica para aumentar datos [@duvalNonparametricTrimFill2000; @duvalTrimFillSimple2000; ver también @duvalTrimFillMethod2005]. Este método puede utilizarse para estimar y ajustar el número y los resultados de los estudios que faltan en un meta-análisis, con base en el escrutinio de un lado de un diagrama de embudo (*funnel plot*) para estimar la asimetría que se supone que se debe al sesgo de publicación. 

Básicamente, el método aumenta los datos observados para que el gráfico de embudo sea más simétrico, y vuelve a calcular la estimación del meta-análisis con base en los datos completos. 

Aunque muy útil, es importante tener en cuenta que método de recorte y relleno (*trim and fill*) tiene algunas limitaciones que deben considerarse:

-  No debe considerarse como una forma de obtener una estimación más "válida" del efecto o resultado global (a partir del meta-análisis), sino como una forma de examinar qué tan sensibles son los resultados a un mecanismo de selección particular (es decir, una forma particular de sesgo de publicación). 

-  Es importante tener en cuenta que este método no se puede usar en modelos con moderadores, como los que explico en la sección \@ref(met-moderation).

En [`metafor`](https://www.metafor-project.org/doku.php), el método de recorte y relleno (*trim and fill*) se hace simplemente con la función `trimfill`, de nuevo usando como argumento el objeto al que asignamos el resultado de nuestro meta-análisis (`res`). En este caso, asignaré el resultado de esta función a un objeto que llamaré `tf`.

```{r}
tf <- trimfill(res)
tf
```

Para crear un *funnel plot* con [`metafor`](https://www.metafor-project.org/doku.php) del meta-análisis con el método de recorte y relleno (*trim and fill*), solo tenemos que usar la función `funnel`, usando
como argumento el objeto al que asignamos los resultados del método de recorte y relleno (`tf`). Con esto, generamos la Figura \@ref(fig:tf-plot1).

```{r tf-plot1, fig.cap = "*Funnel plot* básico de [metafor](https://www.metafor-project.org/doku.php) usando el método de recorte y relleno (*trim and fill*). En negro los estudios meta-analizados; en blanco, los estudios *rellenados*."}
funnel(tf, 
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       ylab = "Error estándar")
```

De nuevo, alternativamente podemos usar la función `viz_funnel` del paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html), para crear este *funnel plot* representando los estudios *rellenados* con el método de recorte y relleno. Sin embargo, para esto usaremos como argumento el meta-análisis original (`res`), pero agregando los argumentos `trim_and_fill = TRUE` y `trim_and_fill_side = "left"` ("left" dado que sabemos que los estudios *faltantes* están a la izquierda del *funnel plot*). 

```{r tf-plot2, fig.cap = "creado con [metaviz](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) usando el método de recorte y relleno (*trim and fill*). En negro los estudios meta-analizados; en blanco, los estudios *rellenados*."}
viz_funnel(res, 
           contours_col = "Oranges",
           trim_and_fill = TRUE, 
           trim_and_fill_side = "left", #IMPORTANTE
           egger = TRUE,
           x_trans_function = tanh,
           ylab = "Error estándar",
           xlab = "Coeficiente de correlación") +
  geom_vline(xintercept = 0, linetype = "dotted")
```

### Estimación del modelo de función de peso

Para determinar el sesgo de publicación, se puede usar la función `weightfunct` del paquete `weightr` [@coburnWeightr2019], que nos permite "estimar tanto el modelo de función de peso para el sesgo de publicación que se publicó originalmente en Vevea y Hedges [-@veveaGeneralLinearModel1995] como la versión modificada presentada en Vevea y Woods [-@veveaPublicationBiasResearch2005]", como se describe en la [documentación](https://www.rdocumentation.org/packages/weightr/versions/2.0.2/topics/weightfunct) de la función `weightfunct`.

```{r message = FALSE}
library(weightr)
```

En este caso, usaré esta función, asignando el resultado a un objeto que llamaré `wf`.

```{r}
wf <- weightfunct(effect = dat$yi, v = dat$vi, table = TRUE)
wf
```

El modelo tradicional nos da un estimado muy similar al des estudio original (0.1486), dado que usa un método ligeramente diferente.

Nos da valores de heterogeneidad $\tau^2$, $\tau$ y $Q$.

Pero lo más importante, es que nos da los resultado del meta-análisis, ajustando los pesos dados a cada efecto, de cada estudio meta-analizado.

Lo que esta función hace es lo que se conoce como *selection models* (modelos de selección). Básicamente, da más peso a ciertos tamaños de efecto. La realidad de la literatura científica es que es más probable que algunos estudios sean publicados, dependiendo de sus valores $p$ (ver SESGO DE PUBLICACIÓN); estudios con valores $p$ mayores a 0.05 (o 0.10), tienen menos probabilidad de ser publicados que estudios con $p < 0.05$.

La función `weightfunct` incrementa el peso de estudios que tienen menos probabilidad de ser publicados, y reduce el peso de estudios con mayor probabilidad de ser publicados. Por esto, al usar ésta técnica, estás asumiendo que de hecho, en el efecto que tratas de encontrar en tu meta-análisis, de hecho hay un sesgo de publicación, lo que a menudo es una suposición bastante justa.

Al usar ésta técnica, tenemos un resultado bastante distinto. Mientras que el meta-análisis original nos daba como resultado un efecto de \~0.15, esta técnica nos estima un efecto de \~0.09. Básicamente, a *encogido* nuestro tamaño de efecto.

Al final el *Likelihood ratio test* (algo así como "Prueba de cociente de probabilidades"), que evalúa la bondad del ajuste de dos modelos estadísticos que compiten entre sí basándose en la relación de su verosimilitud. En este caso, comparando el modelo original, con este modelo con pesos ajustados.

Este resultado nos da una tendencia no descartable (p-val = 0.084043, lo que es \< 0.10; significativa si asumimos un análisis de una cola), que nos da evidencia de que en efecto hay un sesgo de publicación, a pesar de que el *funnel plot* (Figs. \@ref(fig:funnel-plot1), \@ref(fig:funnel-plot1a) \@ref(fig:funnel-plot2) y \@ref(fig:funnel-plot3)) y la regresión de Egger (sección \@ref(reg-egger)), sugerían lo contrario.

# Meta-análisis de correlación con moderador (meta-regresión) {#met-moderation}

\textcolor{red}{Incluir moderadores en nuestro meta-análisis (i.e. hacer una meta-regresión), es una fusión de principios de regresión meta-analíticos y lineales, que sirva para explorar la heterogeneidad. Con esto, podemos saber si existe una asociación lineal entre el resultado de nuestro meta-análisis y una o más covariables.}

\textcolor{red}{La meta-regresión desempeña un papel fundamental en la consideración de los efectos de las covariables, especialmente en presencia de variables categóricas que pueden utilizarse para el análisis de subgrupos.}

## Ejemplo 1: Moderación de la edad promedio de los participantes

Primero, y como ejemplo, vamos a ver si la edad (en nuestros datos, `meanage`) modera el resultado. Esto es importante, pues hay una enorme variación entre las edades medias de los participantes de los diferentes estudios[^6], lo que podría moderar (afectar) la asociación entre concienciación (*conscientiousness*) y adherencia a la medicación prescrita.

[^6]: De hecho, mientras que en el estudio de `r paste0(dat$authors[which.min(dat$meanage)], " (", dat$year[which.min(dat$meanage)], ")")` la edad promedio fue de `r min(dat$meanage)`, en el estudio de `r paste0(dat$authors[which.max(dat$meanage)], " (", dat$year[which.max(dat$meanage)], ")")` la edad promedio fue de `r max(dat$meanage)`.

Para esto, de nuevo podemos usar la función `rma` de paquete `metafor` y de la misma manera que en la sección \@ref(meta-cor), pero agregando nuestra variable moderadora (`meanage`) al argumento `mods`. En este caso voy a asignar a un objeto llamado `res.modage`, para diferenciarlo del objeto `res` al que asigné el meta-análisis básico, sin moderadores.

```{r}
res.modage <- rma(yi = yi, vi = vi, mods = ~meanage, data = dat)
```

Los resultados, son los siguientes:

```{r}
res.modage
```

Los resultados, que tienen la misma organización que los del análisis sin moderadores (sección \@ref(meta-cor)) resultado nos muestra que, a pesar de la gran diferencia de edad entre estudios, la edad no tiene un efecto significativo, como se puede ver en la sección "`Test of Moderators (coefficient 2)`" (al final nos muestra el valor *p* como "\texttt{p-val =  0.2320}"), así como los resultados para el efecto de `meanage` en la tabla `Model Results` (donde nos da el mismo resultado: "\texttt{0.2320}").

### *Forest plot* y *funnel plot* {#plot-mod}

Por supuesto, de estos resultados también puedo crear *forest plots* y *funnel plots*, siguiendo los ejemplos y código de la sección \@ref(meta-cor). Para el *forest plot*, hago a continuación un ejemplo anotado y mejorado (Fig. \@ref(fig:for-plot-mod1), con un código similar al usado como ejemplo en la Fig. \@ref(fig:for-plot2)). Sin embargo, es importante tener en cuenta que esta opción no creará un resumen del meta-análisis, ya que no tenemos un solo efecto *real* como producto del meta-análisis.

```{r eval = FALSE}
# forest plot con anotaciones adicionales
forest(res.modage,  cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
par(cex = 0.8, font = 2)
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

```{r for-plot-mod1, echo = FALSE, warning = FALSE, fig.height = 3.5, fig.cap = "Forest plot básico de [metafor](https://www.metafor-project.org/doku.php), para un meta-análisis incluyendo la edad promedio de los participantes como moderador. En la ilustración gráfica, además de los efectos originales, se puede ver el efecto de cada estudio estimado cuando se incluye el moderador como polígonos (diamantes) de color gris. Sin embargo, ya no obtenemos una fila al final representando el efecto promediado del meta-análisis, ya que no tenemos un solo efecto."}
# forest plot con anotaciones adicionales
par(mar = c(4,0,0,0))
forest(res.modage,  cex = 0.75, xlim = c(-1.6, 1.6),
       slab = paste(dat$authors, dat$year, sep = ", "),
       showweights = TRUE,
       xlab = "Coeficiente de correlación transformado en z de Fisher",
       digits = c(2,3L))
# agregar encabezados a las columnas (valores de X y Y deben ser ajustados)
par(cex = 0.8, font = 2)
text(x = -1.6, y = 18, labels = "Autor(es), Año", pos = 4)
text(x = 0, y = 18, labels = "Efecto e IC", pos = 4)
text(x = 1, y = 18, labels = "Peso", pos = 2)
text(x = 1.6, y = 18, labels = "Corr. [95% IC]", pos = 2)
```

Es importante tener en cuenta que la función [`viz_forest`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html#creating-forest-plots-with-function-viz_forest) del paquete [`metaviz`](https://cran.r-project.org/web/packages/metaviz/vignettes/metaviz.html) tendrá problemas para crear un *forest plot* de un meta-análisis con moderadores).

De manera similar, podemos obtener un *funnel plot* de nuestro meta-análisis con moderador. Es importante tener en cuenta que tanto el paquete `weightr` como el paquete `metafor` tienen funciones llamadas `funnel`. Dado que cargamos el paquete `weightr` después, R por defecto intentará intentará crear el *funnel plot* con la función `funnel` del paquete `weightr`, en vez de la función `funnel` del paquete `metafor`. Para evitar este error, tenemos dos opciones: podemos pedirle a R explícitamente que use la función `funnel` del paquete `metafor` con el comando `metafor::funnel`, o podemos pedirle a R que elimine el paquete de la memoria con la función `detach("package:metameta", unload = TRUE)`. En este caso, usaré la primera opción.

Este *funnel plot*, a diferencia los los anteriores, nos mostrará los valores residuales de cada estudio (es decir, qué tanto se alejan del resultado de nuestro meta-análisis, que tiene un valor residual de 0; Fig. \@ref(fig:funnel-plot1)), en vez de los coeficientes de correlación (transformados a $z$ de Fisher).

```{r eval = FALSE}
metafor::funnel(res.modage,
                xlab = "Valor residual",
                ylab = "Error estándar")
```

```{r funnel-plot-mod1, echo = FALSE, fig.height = 5, fig.cap = "Funnel plot básico de [metafor](https://www.metafor-project.org/doku.php), para un meta-análisis incluyendo la edad promedio de los participantes como moderador, y con títulos de los ejes en español. La línea punteada vertical representa el efecto meta-analizado que hemos encontrado, así que podemos ver los estudios que encontraron un efecto mayor (derecha de la línea punteada) o menor (izquierda) de éste. **Nota**: Para evitar confunción entre las funciones `funnel` de los paquetes `weightr` y `metafor`, en este caso he usado el comando \\texttt{metafor::funnel} para pedirle a R explícitamente que use la función `funnel` del paquete `metafor`."}
par(mar = c(4,4,0,1))
metafor::funnel(res.modage,
                xlab = "Valor residual",
                ylab = "Error estándar")
```

### *Meta-Analytic Scatter Plot* (Gráfico de dispersión meta-analítico)

Cuando tenemos un modelo con moderador, también podemos ver la asociación entre la variable moderadora, y el efecto de cada estudio meta-analizado, a modo de regresión. La función `regplot` hace precisamente esto (Fig. \@ref(fig:reg-plot)).

```{r reg-plot, fig.cap = "Gráfico de dispersión meta-analítico (*Meta-Analytic Scatter Plot*). El tamaño de los puntos es proporcional al peso que recibieron los estudios en el meta-análisis (puntos más grandes para los estudios con más peso). La línea negra representa el efecto previsto en función del predictor (en este caso \\texttt{age}, edad) con intervalo de confianza del 95%."}
regplot(res.modage,
        ylab = "Coeficiente de correlación transformado en z de Fisher",
        xlab = "Edad promedio del estudio")
```


```{r}
# Calcular efecto ajustado para diferentes edades
pred.res.modage <- predict(res.modage, newmods = seq(20, 80, by = 10)) %>% 
  as_tibble() %>% 
  mutate(meanage = seq(20, 80, by = 10)) %>% 
  select(7, 1:6)
pred.res.modage
```

## Ejemplo 2: Moderación de las controles usados en cada estudio meta-analizado

Como segundo ejemplo, voy a mirar si el hecho de que los estudios tengan variables que fueron controladas, modera la asociación entre concienciación (*conscientiousness*) y adherencia a la medicación prescrita. Siguiendo los mismos pasos, voy hacer éste análisis, pero voy a asignar este meta-análisis a un objeto llamado `res.contr`. 

```{r}
res.contr <- rma(yi = yi, vi = vi, mods = ~controls, data = dat)
res.contr

regplot(res.contr,
        ylab = "Coeficiente de correlación transformado en z de Fisher",
        xlab = "Controles (0 = ninguno; 1 = múltiples)")

pred.res.contr <- predict(res.contr, newmods = c(0, 1)) %>% 
  as_tibble() %>% 
  mutate(controls = levels(dat$controls)) %>% 
  rename(yi = pred) %>% 
  select(9, 1:8)

ggplot(dat, aes(x = controls, y = yi)) +
  geom_point(aes(size = ni, color = ni),
             alpha = 0.5) +
  scale_color_viridis_c(option = "inferno", guide = "legend") +
  scale_size_continuous(range = c(1, 10)) +
  guides(color = guide_legend(), 
         size = guide_legend()) +
  scale_x_discrete(labels=c("none" = "Ninguno", 
                            "multiple" = "Múltiples")) +
  labs(x = "Controles", 
       y = " Coeficiente de correlación \n transformado en z de Fisher ") +
  geom_errorbar(data = pred.res.contr,
                mapping = aes(ymin = ci.lb, ymax = ci.ub),
                width = 0.1,
                color = "black") +
  geom_point(data = pred.res.contr,
             shape = 21, size = 3,
             color = "black", fill = "white") +
  labs(color = "Tamaño de muestra",
       size = "Tamaño de muestra") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

En éste caso, a diferencia del ejemplo de moderación anteriores, la variable moderadora (`controls`) sí tiene un efecto significativo, como se puede ver en la columna `pval` para el efecto de `controlsnone` (`r scales::pvalue(res.contr$pval[2])`), y en los asteriscos que aparecen al final de esa fila (`***`).

Por supuesto, *forest plots* y *funnel plots* pueden ser creados, tal y como describí en la sección \@ref(plot-mod).

# Poder estadístico del meta-análisis

En esta sección explicaré cómo hacer un análisis de poder de un meta-análisis; la idea de ésto es saber si nuestro meta-análisis tiene un poder suficiente para detectar el efecto meta-analizado (en nuestro caso `r round(min(res$beta[1]), 2)` para el meta-análisis original "`res`", o `r round(wf$output_adj$par[2], 2)` el meta-análisis con pesos ajustados "`wf`"). Para este ejemplo, asumiré que el efecto *real* es el encontrado en nuestro análisis original (`r round(min(res$beta[1]), 2)`), pues este efecto es más mayor. Si no tuviésemos el poder suficiente para detectar confiablemente ese efecto, menos lo tendríamos para un efecto menor, como el detectado en nuestro meta-análisis con pesos ajustados.

Para hacer esto, usaré el paquete `metameta` [@quintanaMetameta2022], que permite calcular y visualizar el poder estadístico de un meta-análisis para detectar un rango de posibles efectos *reales*.

## Instalación de `metameta`

El paquete `metameta` se debe instalar desde GitHub[^7] ya que, al día de hoy, no está aún disponible en CRAN.

[^7]: [GitHub](https://github.com/) es un repositorio abierto para para proyectos de código abierto en el que, entre otras cosas, suelen estar alojados todos los paquetes de R incluso en versiones de desarrollador. Por supuesto, a diferencia de [CRAN](https://cran.r-project.org/), GitHub no es ni mucho menos específico para paquetes de R.

Para esto, debemos tener instalado el paquete `devtools`, y usar la función `install_github` que nos permite instalar paquetes directamente desde GitHub.

```{r eval = FALSE}
#se debe tener instalado el paquete devtools
library(devtools)
install_github("dsquintana/metameta")
```

## Análisis de poder

Una vez instalado, podemos cargar el paquete.

```{r}
library(metameta)
```

Como datos, necesitamos no solamente los tamaños de datos a meta-analizar ($r$ de Pearson transformado a *z* de Fisher), sino además los intervalos de confianza, tal como fueron reportados en varios de nuestros *Forest plots*.

En este caso, voy a asumir un *efecto real* de $r = 0.15$, tal como en nuestro meta-análisis original. Sin embargo, el *efecto real* no es algo que podamos saber (es, de hecho, lo que queremos acercarnos a conocer a través del meta-análisis), así que la función `mapower_ul` del paquete `metameta` calcula el poder de cada meta-análisis para un rango de posibles efectos reales.

```{r}
dat.power <- summary(dat) %>%
  select(yi, ci.lb, ci.ub) %>%
  rename(lower = ci.lb, upper = ci.ub)
power <- mapower_ul(dat = dat.power, observed_es = 0.15, name = "Molloy et al. 2014")

power_dat <- power$dat
power_dat
```

## Visualización del análisis de poder (*Firepower plot*)

Según esto, nuestro meta-análisis solo tiene un poder estadístico suficiente para detectar de manera confiable efectos mayores a 0.4, lo que está muy por encima de nuestras estimaciones de un efecto real (0.15 en nuestro meta-análisis original, 0.09 en nuestro meta-análisis con pesos ajustados)

```{r}
power_list <- list(power$power_median_dat)
power.plot <- firepower(power_list)
```

Para ver el *fireplot* que creamos, y ya que lo asigné a un objeto que llamé `power.plot`, debo correr el objeto para ver el resultado (Fig. \@ref(fig:fire-plot1)).

```{r eval = FALSE}
power.plot
```

```{r fire-plot1, fig.height = 2, echo = FALSE, fig.cap = "Fireplot básico de [metameta](https://www.dsquintana.blog/metameta-r-package-meta-analysis/), para un análisis de poder de nuestro meta-análisis. *Observed* hace referencia al tamaño de efecto observado en nuestro meta-análisis original; en este caso, 0.15."}
power.plot$fp_plot
```

Si queremos cambiar los títulos a español, y ya que el objeto `power.plot` contiene dos elementos (`dat` y `fp_plot`, que es propiamente la gráfica). Éste último elemento es de clase `ggplot`, por lo que podemos usar funciones de `ggplot2` para cambiar, por ejemplo, el título del eje $X$ a "Tamaño de efecto", el título de la leyenda a "Poder", y el efecto observado de "*Observed*" a "Observado"[^8] (Fig. \@ref(fig:fire-plot2)). Por ejemplo:

[^8]: Para cambiar el título del eje $X$ usé la función `xlab`; para el título de la leyenda la función `guides` (opción `fill = guide_legend`); y para los valores del eje $X$, la función `scale_x_discrete`}.

```{r fire-plot2, fig.height = 2, message = FALSE, fig.cap = "Fireplot básico de [metameta](https://www.dsquintana.blog/metameta-r-package-meta-analysis/), para un análisis de poder de nuestro meta-análisis, con el texto traducido a español y con la leyenda en una escala discreta para facilitar su lectura. *Observado* hace referencia al tamaño de efecto observado en nuestro meta-análisis original (en este caso, 0.15)."}
power.plot$fp_plot +
  xlab("Tamaño de efecto") +
  guides(fill = guide_legend(title = "Poder", 
                             reverse = TRUE)) +
  scale_x_discrete(labels = c("es_observed" = "Observado",
                              "es01" = 0.1,    
                              "es02" = 0.2,
                              "es03" = 0.3,
                              "es04" = 0.4,    
                              "es05" = 0.5,    
                              "es06" = 0.6,    
                              "es07" = 0.7,
                              "es08" = 0.8,
                              "es09" = 0.9,
                              "es1"  = 1))
```

\newpage

# APÉNDICES {.unnumbered}

## Alternativas a `metafor` {.unnumbered}

Acá he usado principalmente una ruta para hacer meta-análisis basada en el paquete `metafor`, acompañado de `metaviz` para visualizaciones, `weightr` para ajustar pesos y detectar sesgos de publicación, y `metameta` para estimar el poder estadístico de un meta-análisis.

Sin embargo, existen rutas alternativas para realizar meta-análisis en R. El libro *Doing meta-analysis with R: a hands-on guide* [@harrer2021doing] se acompaña del paquete [`dmetar`](https://dmetar.protectlab.org/index.html) [@Harrer2019dmetar], que contiene opciones para hacer meta-análisis tanto a partir de `metafor`, como a partir de `meta` [@BalduzziMeta2019; @schwarzerMetaAnalysis2015].

De manera importante, los objetos generados por `meta` al realizar un meta-análisis permiten hacer otros análisis como *risk of bias* (riesgo de sesgo), inferencia multi-modelo, detección de *outliers* (valores atípicos), o *p-curve* (curva de valores $p$), así como opciones para hacer gráficos distintos. Para una guía resumida y concreta (en inglés) de estas opciones, recomiendo ver el sitio web del paquete [`dmetar`](http://dmetar.protectlab.org/), y en especial la página [*Get Started*](https://dmetar.protectlab.org/articles/dmetar.html).

## Citas y referencias de paquetes de R {.unnumbered}

Por supuesto, los paquetes de R que usemos deben ser citados. Una manera fácil de encontrar la cita que los autores de un paquete quieren que usemos, es la función `citation` en R. Simplemente debemos usar esta función, agregando como argumento el nombre del paquete que queremos citar entre comillas. Esto nos dará la referencia en un formato estándar, así como como en un formato `BibTex` que puede ser usado en documentos \LaTeX, o por muchos gestores de referencia (alternativamente nos permite saber los campos como autores, título y demás, si vamos a crear las citas y referencias manualmente).

Por ejemplo, en ésta guía usé `dplyr` [@WickhamDplyr2021] para manipular los datos, y usando la función `citation`, obtengo esta información:

```{r}
citation("dplyr")
```

\newpage

# Referencias
